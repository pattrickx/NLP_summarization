{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "summarization.ipynb",
      "provenance": [],
      "mount_file_id": "11Gewmi-FTFmhdhWlVgeR42rfdoczEDJh",
      "authorship_tag": "ABX9TyPZx7yi31+1ymWYIjezD23P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pattrickx/NLP_summarization/blob/main/summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sumarisação por frequencia\n"
      ],
      "metadata": {
        "id": "IQjA5CtmF54v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install goose3\n",
        "!python -m spacy download pt"
      ],
      "metadata": {
        "id": "bSSDHsDkhv4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEL5gUoRT1bD"
      },
      "outputs": [],
      "source": [
        "from IPython.core.display import HTML\n",
        "from goose3 import Goose\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import heapq\n",
        "import spacy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spa_NLP = spacy.load('pt')\n",
        "spa_NLP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eFebeak_Djz",
        "outputId": "3b8837c4-7225-4f9d-9312-1981ebf6fd18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.pt.Portuguese at 0x7f5b767ac0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ_EcqWp9zQm",
        "outputId": "846bbb55-f887-4021-ff10-7607b7a48f5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = nltk.corpus.stopwords.words('portuguese')"
      ],
      "metadata": {
        "id": "71fc_xt4GlYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_base = \"\"\"A inteligência artificial é a inteligência similar à humana.\n",
        "Definem como o estudo de agente artificial com inteligência.\n",
        "Ciência e engenharia de produzir máquinas com inteligência.\n",
        "Resolver problemas e possuir inteligência. \n",
        "Relacionada ao comportamento inteligente.\n",
        "Construção de máquinas para raciocinar. \n",
        "Aprender com os erros e acertos.\n",
        "Inteligência artificial é raciocinar nas situações do cotidiano.\"\"\""
      ],
      "metadata": {
        "id": "hx3ReHVSUAnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"/content/drive/MyDrive/My_projects/sumarização/text.txt\", \"r\")\n",
        "text_base = f.read()\n",
        "f.close()"
      ],
      "metadata": {
        "id": "Ld8wB0yNVhZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_process(text_base)"
      ],
      "metadata": {
        "id": "08af56c_9lQM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "fbd0c852-96e1-4715-b87c-471c9e95d667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"processamento língua natural pln subárea ciência computação inteligência artificial linguística estuda problemas geração compreensão automática línguas humanas naturais sistemas geração língua natural convertem informação bancos dados computadores linguagem compreensível ser humano sistemas compreensão língua natural convertem ocorrências linguagem humana representações formais facilmente manipuláveis programas computador alguns desafios pln compreensão língua natural fazer computadores extraiam sentido linguagem humana natural geração língua natural história pln começou década alan turing publicou artigo `` computing machinery and intelligence '' propunha agora chamado teste turing critério inteligência experiência georgetown envolveu tradução automática sessenta frases russas inglês autores afirmaram dentro três cinco anos tradução automática problema resolvido entanto avanços reais lentos previsto após relatório alpac constatou pesquisa dez anos conseguiu satisfazer expectativas financiamento estudo tradução automática reduzido drasticamente poucas pesquisas tradução automática conduzidas final anos primeiros sistemas estatísticos tradução desenvolvidos alguns sistemas pln bem sucedidos desenvolvidos anos shrdlu sistema língua natural trabalhava `` blocks worlds '' vocabulário restrito eliza simulação psicoterapeuta escrita joseph weizenbaum usando pouca informação sobre pensamento emoção humana eliza criava alguns casos interações surpreendentemente humanas `` paciente '' excedia base conhecimento programa eliza fornecia resposta genérica exemplo respondendo `` cabeça dói '' `` diz cabeça dói '' durante década muitos programadores começaram escrever `` ontologias conceituais '' estruturaram informação mundo real dados compreensíveis computadores exemplos margie schank sam cullingford pam wilensky talespin meehan qualm lehnert politics carbonell plot units lehnert neste período muitos chatterbots escritos parry racter jabberwacky década maioria sistemas pln baseava conjuntos complexos regras manuscritas partir final anos entanto revolução pln introdução algoritmos aprendizagem automática aprendizado máquina processamento linguagem devido tanto aumento constante poder computacional ver lei moore quanto diminuição gradual dominância teorias linguística chomskyanas gramática gerativa cujos fundamentos teóricos desestimularam tipo corpus linguístico subjacente abordagem aprendizagem automática processamento linguagem alguns algoritmos aprendizado máquinas antigos árvores decisão produziam sistemas regras rígidas então semelhantes regras existentes escritas mão entanto marcação partes fala part-of-speech tagging introduziu uso modelos ocultos markov pln cada vez pesquisa concentrava modelos estatísticos tomam decisões suaves probabilísticas baseadas atribuição pesos reais recursos compõem dados entrada modelos linguagem cache sobre quais muitos sistemas reconhecimento fala agora dependem exemplos tais modelos estatísticos modelos geralmente robustos dados informações desconhecidas especialmente entrada contém erros comum dados mundo real produzem resultados confiáveis integrados sistemas maiores compreendem múltiplas tarefas muitos sucessos iniciais notáveis ocorreram campo tradução automática devido especialmente trabalho pesquisa ibm desenvolveu modelos estatísticos elaborados sistemas capazes tirar proveito corpora textuais multilíngues existentes produzidos parlamento canadá união europeia resultado leis exigem tradução todos processos governamentais todas línguas oficiais países entanto maioria sistemas dependia corpora desenvolvido especificamente tarefas implementadas sistemas muitas vezes continua sendo grande limitação sucesso resultado grande quantidade pesquisa passou quantidades dados limitadas métodos aprendizagem eficazes pesquisas recentes têm concentrado cada vez algoritmos aprendizagem semi-supervisionados supervisão algoritmos capazes aprender dados anotados manualmente respostas desejadas usando combinação dados anotados anotados geralmente tarefa trabalhosa aprendizagem supervisionada normalmente produz resultados menos precisos quantidade específica dados entrada entanto enorme quantidade dados anotados disponíveis incluindo outras coisas todo conteúdo world wide web muitas vezes pode compensar resultados inferiores \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_process(text_base):\n",
        "    text = re.sub(r'\\s+',' ',text_base.lower())\n",
        "    text = re.sub(r'[0-9]', \" \", text)\n",
        "\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    # tokens = []\n",
        "    # for token in spa_NLP(text):\n",
        "    #     tokens.append(token.lemma_)\n",
        "\n",
        "    new_text = \"\"\n",
        "    for i in tokens:\n",
        "        if not  i in stopwords and not i in string.punctuation:\n",
        "            new_text += f\"{i} \"\n",
        "\n",
        "    return new_text"
      ],
      "metadata": {
        "id": "TYaUmctE8aQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_summarization(text_base,n_sent=5,titulo= \"\"):\n",
        "    sent_list_base = nltk.sent_tokenize(text_base)\n",
        "\n",
        "    processed_text = pre_process(text_base)\n",
        "    word_frequency = nltk.FreqDist(nltk.word_tokenize(processed_text))\n",
        "    max_frequency  = max(word_frequency.values())\n",
        "\n",
        "    for word in word_frequency:\n",
        "        word_frequency[word] = word_frequency[word]/max_frequency \n",
        "\n",
        "\n",
        "    \n",
        "    sent_notes = {}\n",
        "    for sent in sent_list_base:\n",
        "        sent_procesed  = pre_process(sent)\n",
        "        note = 0 \n",
        "        for word in nltk.word_tokenize(sent_procesed):\n",
        "            note +=  word_frequency[word]\n",
        "        \n",
        "        sent_notes[sent] = note\n",
        "\n",
        "    bests_sent = heapq.nlargest(n_sent,sent_notes, key = sent_notes.get)\n",
        "\n",
        "\n",
        "    final_text = f'<H1>Resumo {titulo} </H1>'\n",
        "    for sent in sent_list_base:\n",
        "        if sent in bests_sent:\n",
        "            final_text +=str(sent).replace(sent,f\"<mark>{sent}</mark>\")\n",
        "        else:\n",
        "            final_text += sent\n",
        "    display(HTML(f\"\"\"{final_text}\"\"\"))"
      ],
      "metadata": {
        "id": "3G5FTKbIW1D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_summarization(text_base)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "_MRMus5MX4PF",
        "outputId": "43f7c0a6-87d6-485a-c942-cb50bd969ecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<H1>Resumo  </H1>Processamento de língua natural (PLN) é uma subárea da ciência da computação, inteligência artificial e da linguística que estuda os problemas da geração e compreensão automática de línguas humanas naturais.<mark>Sistemas de geração de língua natural convertem informação de bancos de dados de computadores em linguagem compreensível ao ser humano e sistemas de compreensão de língua natural convertem ocorrências de linguagem humana em representações mais formais, mais facilmente manipuláveis por programas de computador.</mark><mark>Alguns desafios do PLN são compreensão de língua natural, fazer com que computadores extraiam sentido de linguagem humana ou natural e geração de língua natural.</mark>A história do PLN começou na década de 1950, quando Alan Turing publicou o artigo \"Computing Machinery and Intelligence\", que propunha o que agora é chamado de teste de Turing como critério de inteligência.Em 1954, a experiência de Georgetown envolveu a tradução automática de mais de sessenta frases russas para o inglês.Os autores afirmaram que dentro de três ou cinco anos a tradução automática seria um problema resolvido.[2] No entanto, os avanços reais foram muito mais lentos do que o previsto e, após o relatório ALPAC em 1966, que constatou que a pesquisa de dez anos não conseguiu satisfazer as expectativas, o financiamento para este estudo em tradução automática foi reduzido drasticamente.Poucas pesquisas em tradução automática foram conduzidas até o final dos anos 80, quando os primeiros sistemas estatísticos de tradução foram desenvolvidos.<mark>Alguns sistemas de PLN bem sucedidos desenvolvidos nos anos 60 foram SHRDLU, um sistema de língua natural que trabalhava em \"blocks worlds\" com vocabulário restrito e ELIZA, uma simulação de um psicoterapeuta escrita por Joseph Weizenbaum entre 1964 e 1966.</mark>Usando pouca informação sobre o pensamento ou a emoção humana, ELIZA criava, em alguns casos, interações surpreendentemente humanas.Quando o \"paciente\" excedia a base de conhecimento do programa, ELIZA fornecia uma resposta genérica, por exemplo, respondendo a \"Minha cabeça dói\" com \"Por que você diz que sua cabeça dói?\".Durante a década de 1970, muitos programadores começaram a escrever \"ontologias conceituais\", que estruturaram a informação do mundo real em dados compreensíveis por computadores.Exemplos são MARGIE (SCHANK, 1975), SAM (CULLINGFORD, 1978), PAM (WILENSKY, 1978), TaleSpin (MEEHAN, 1976), QUALM (LEHNERT, 1977), Politics (CARBONELL, 1979) e Plot Units (LEHNERT, 1981 ).Neste período, muitos chatterbots foram escritos, como PARRY, Racter e Jabberwacky.Até a década de 1980, a maioria dos sistemas de PLN se baseava em conjuntos complexos de regras manuscritas.A partir do final dos anos 1980, no entanto, houve uma revolução no PLN com a introdução de algoritmos de aprendizagem automática (aprendizado de máquina) para o processamento de linguagem.Isto foi devido tanto ao aumento constante do poder computacional (ver Lei de Moore) quanto à diminuição gradual da dominância das teorias da linguística chomskyanas (como a gramática gerativa), cujos fundamentos teóricos desestimularam o tipo de corpus linguístico que está subjacente à abordagem da aprendizagem automática ao processamento da linguagem[3].Alguns dos algoritmos de aprendizado de máquinas mais antigos, como as árvores de decisão, produziam sistemas de regras rígidas então semelhantes às regras existentes na escritas à mão.<mark>No entanto, a marcação de partes da fala (part-of-speech tagging) introduziu o uso de modelos ocultos de Markov para o PLN e, cada vez mais, a pesquisa se concentrava em modelos estatísticos, que tomam decisões suaves e probabilísticas baseadas na atribuição de pesos reais aos recursos que compõem dados de entrada.</mark>Os modelos de linguagem de cache, sobre os quais muitos sistemas de reconhecimento de fala agora dependem, são exemplos de tais modelos estatísticos.<mark>Esses modelos são geralmente mais robustos quando dados informações desconhecidas, especialmente entrada que contém erros (como é muito comum para dados do mundo real) e produzem resultados mais confiáveis quando integrados em sistemas maiores que compreendem múltiplas tarefas.</mark>Muitos dos sucessos iniciais notáveis ocorreram no campo da tradução automática, devido especialmente ao trabalho de pesquisa da IBM, que desenvolveu modelos estatísticos mais elaborados.Estes sistemas foram capazes de tirar proveito de corpora textuais multilíngues existentes produzidos pelo Parlamento do Canadá e a União Europeia como resultado de leis que exigem a tradução de todos os processos governamentais em todas as línguas oficiais dos países.No entanto, a maioria dos sistemas dependia de corpora desenvolvido especificamente para tarefas implementadas por esses sistemas, o que era (e muitas vezes continua sendo) uma grande limitação no sucesso dos mesmo.Como resultado, uma grande quantidade de pesquisa passou de quantidades de dados limitadas a métodos de aprendizagem mais eficazes.Pesquisas recentes têm se concentrado cada vez mais em algoritmos de aprendizagem semi-supervisionados e sem supervisão.Esses algoritmos são capazes de aprender com dados que não foram anotados manualmente com as respostas desejadas ou usando uma combinação de dados anotados e não anotados.Geralmente, esta tarefa é muito mais trabalhosa do que a aprendizagem supervisionada e normalmente produz resultados menos precisos para uma quantidade específica de dados de entrada.No entanto, há uma enorme quantidade de dados não anotados disponíveis (incluindo, entre outras coisas, todo o conteúdo da World Wide Web), que muitas vezes pode compensar os resultados inferiores."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gse = Goose()\n",
        "article = gse.extract(\"https://pt.wikipedia.org/wiki/Processamento_de_linguagem_natural\")\n",
        "article.infos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmYDaoW1hkor",
        "outputId": "6213f0ba-a2d7-45ff-e5a6-a3358c804b3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'authors': [],\n",
              " 'cleaned_text': 'Processamento de língua natural (PLN) é uma subárea da ciência da computação, inteligência artificial e da linguística que estuda os problemas da geração e compreensão automática de línguas humanas naturais. Sistemas de geração de língua natural convertem informação de bancos de dados de computadores em linguagem compreensível ao ser humano e sistemas de compreensão de língua natural convertem ocorrências de linguagem humana em representações mais formais, mais facilmente manipuláveis por programas de computador. Alguns desafios do PLN são compreensão de língua natural, fazer com que computadores extraiam sentido de linguagem humana ou natural e geração de língua natural.\\n\\nA história do PLN começou na década de 1950, quando Alan Turing publicou o artigo \"Computing Machinery and Intelligence\", que propunha o que agora é chamado de teste de Turing como critério de inteligência.\\n\\nEm 1954, a experiência de Georgetown envolveu a tradução automática de mais de sessenta frases russas para o inglês. Os autores afirmaram que dentro de três ou cinco anos a tradução automática seria um problema resolvido.[2] No entanto, os avanços reais foram muito mais lentos do que o previsto e, após o relatório ALPAC em 1966, que constatou que a pesquisa de dez anos não conseguiu satisfazer as expectativas, o financiamento para este estudo em tradução automática foi reduzido drasticamente. Poucas pesquisas em tradução automática foram conduzidas até o final dos anos 80, quando os primeiros sistemas estatísticos de tradução foram desenvolvidos.\\n\\nAlguns sistemas de PLN bem sucedidos desenvolvidos nos anos 60 foram SHRDLU, um sistema de língua natural que trabalhava em \"blocks worlds\" com vocabulário restrito e ELIZA, uma simulação de um psicoterapeuta escrita por Joseph Weizenbaum entre 1964 e 1966. Usando pouca informação sobre o pensamento ou a emoção humana, ELIZA criava, em alguns casos, interações surpreendentemente humanas. Quando o \"paciente\" excedia a base de conhecimento do programa, ELIZA fornecia uma resposta genérica, por exemplo, respondendo a \"Minha cabeça dói\" com \"Por que você diz que sua cabeça dói?\".\\n\\nDurante a década de 1970, muitos programadores começaram a escrever \"ontologias conceituais\", que estruturaram a informação do mundo real em dados compreensíveis por computadores. Exemplos são MARGIE (SCHANK, 1975), SAM (CULLINGFORD, 1978), PAM (WILENSKY, 1978), TaleSpin (MEEHAN, 1976), QUALM (LEHNERT, 1977), Politics (CARBONELL, 1979) e Plot Units (LEHNERT, 1981 ). Neste período, muitos chatterbots foram escritos, como PARRY, Racter e Jabberwacky.\\n\\nAté a década de 1980, a maioria dos sistemas de PLN se baseava em conjuntos complexos de regras manuscritas. A partir do final dos anos 1980, no entanto, houve uma revolução no PLN com a introdução de algoritmos de aprendizagem automática (aprendizado de máquina) para o processamento de linguagem. Isto foi devido tanto ao aumento constante do poder computacional (ver Lei de Moore) quanto à diminuição gradual da dominância das teorias da linguística chomskyanas (como a gramática gerativa), cujos fundamentos teóricos desestimularam o tipo de corpus linguístico que está subjacente à abordagem da aprendizagem automática ao processamento da linguagem[3].\\n\\nAlguns dos algoritmos de aprendizado de máquinas mais antigos, como as árvores de decisão, produziam sistemas de regras rígidas então semelhantes às regras existentes na escritas à mão. No entanto, a marcação de partes da fala (part-of-speech tagging) introduziu o uso de modelos ocultos de Markov para o PLN e, cada vez mais, a pesquisa se concentrava em modelos estatísticos, que tomam decisões suaves e probabilísticas baseadas na atribuição de pesos reais aos recursos que compõem dados de entrada. Os modelos de linguagem de cache, sobre os quais muitos sistemas de reconhecimento de fala agora dependem, são exemplos de tais modelos estatísticos. Esses modelos são geralmente mais robustos quando dados informações desconhecidas, especialmente entrada que contém erros (como é muito comum para dados do mundo real) e produzem resultados mais confiáveis quando integrados em sistemas maiores que compreendem múltiplas tarefas.\\n\\nMuitos dos sucessos iniciais notáveis ocorreram no campo da tradução automática, devido especialmente ao trabalho de pesquisa da IBM, que desenvolveu modelos estatísticos mais elaborados. Estes sistemas foram capazes de tirar proveito de corpora textuais multilíngues existentes produzidos pelo Parlamento do Canadá e a União Europeia como resultado de leis que exigem a tradução de todos os processos governamentais em todas as línguas oficiais dos países. No entanto, a maioria dos sistemas dependia de corpora desenvolvido especificamente para tarefas implementadas por esses sistemas, o que era (e muitas vezes continua sendo) uma grande limitação no sucesso dos mesmo. Como resultado, uma grande quantidade de pesquisa passou de quantidades de dados limitadas a métodos de aprendizagem mais eficazes.\\n\\nPesquisas recentes têm se concentrado cada vez mais em algoritmos de aprendizagem semi-supervisionados e sem supervisão. Esses algoritmos são capazes de aprender com dados que não foram anotados manualmente com as respostas desejadas ou usando uma combinação de dados anotados e não anotados. Geralmente, esta tarefa é muito mais trabalhosa do que a aprendizagem supervisionada e normalmente produz resultados menos precisos para uma quantidade específica de dados de entrada. No entanto, há uma enorme quantidade de dados não anotados disponíveis (incluindo, entre outras coisas, todo o conteúdo da World Wide Web), que muitas vezes pode compensar os resultados inferiores.\\n\\nOs algoritmos modernos de PLN baseiam-se na aprendizagem mecânica, especialmente na aprendizagem de máquinas estatísticas. O paradigma da aprendizagem mecânica é diferente do da maioria das tentativas anteriores de processamento da linguagem. Anteriormente, implementações de tarefas de processamento de linguagem envolviam a codificação direta de grandes conjuntos de regras. O paradigma da aprendizagem automática (ou aprendizagem automática) induz a aprendizagem automática de regras através de análises de corpora de exemplos típicos do mundo real ao invés de usar algoritmos gerais de aprendizagem (muitas vezes, embora nem sempre, baseados em inferência estatística). Um corpus (plural \"corpora\") é um conjunto de documentos (ou frases individuais) que foram anotados à mão com os valores corretos a serem aprendidos.\\n\\nMuitas classes diferentes de algoritmos de aprendizado de máquina foram aplicadas a tarefas de PLN. Esses algoritmos tomam como entrada um grande conjunto de \"recursos\" que são gerados a partir de dados de entrada.\\n\\nAlguns dos algoritmos mais usados, como árvores de decisão, produziam sistemas de regras rígidas semelhantes aos sistemas de regras manuscritas mais comuns. No entanto, cada vez mais, a pesquisa tem se concentrado em modelos estatísticos, que tomam decisões flexíveis e probabilísticas baseadas em agregar pesos reais a cada característica de entrada. Tais modelos têm a vantagem de poder expressar a certeza relativa de muitas respostas possíveis diferentes em vez de apenas uma, produzindo resultados mais confiáveis quando esse modelo é incluído como um componente de um sistema maior.\\n\\nOs sistemas baseados em algoritmos de aprendizagem mecânica têm muitas vantagens em relação às regras produzidas manualmente:\\n• Os procedimentos de aprendizagem usados durante a aprendizagem da máquina focam-se automaticamente nos casos mais comuns, ao passo que quando se escrevem regras à mão, não é óbvio em que sentido o esforço deve ser dirigido.\\n• Os procedimentos de aprendizagem automática podem fazer uso de algoritmos de inferência estatística para produzir modelos que são robustos a entradas não familiares (por exemplo, contendo palavras ou estruturas que não foram vistas antes) e a entradas errôneas (por exemplo, com palavras ou palavras incorretamente omitidas). Geralmente, lidar com essas entradas de forma com regras manuscritas ou sistemas de regras manuscritas que tomam decisões suaves é extremamente trabalhoso, propenso a erros e demorado.\\n• Sistemas baseados em aprender automaticamente as regras podem ser mais precisos simplesmente fornecendo mais dados de entrada. No entanto, os sistemas baseados em regras escritas à mão só podem ser tornados mais precisos aumentando a complexidade das regras, o que é uma tarefa muito mais difícil. Em particular, há um limite para a complexidade de sistemas baseados em regras artesanais, para além dos quais os sistemas se tornam cada vez mais incontroláveis. No entanto, a criação de mais dados para entrada em sistemas de aprendizado de máquina requer simplesmente um aumento correspondente no número de horas trabalhadas por humanos, geralmente sem aumentos significativos na complexidade do processo de anotação.\\n\\nO subcampo de PLN dedicado a abordagens de aprendizagem é conhecido como aprendizagem de língua natural (NLL) e sua conferência, a CoNLL,[4] e orgão central, o SIGNLL,[5] são patrocinados pela ACL, reconhecendo também as suas ligações com linguística computacional e aquisição de linguagem. Quando o objetivo da pesquisa de aprendizagem de linguagem computacional é entender mais sobre aquisição de linguagem humana, ou psicolinguística, a NLL sobrepõe-se no campo relacionado de psicolinguística computacional.\\n\\nA listagem a seguir traz alguns dos trabalhos mais pesquisadas em PLN. Note que alguns deles têm aplicações no mundo real, enquanto outras servem mais frequentemente como tarefas secundárias que são usadas para auxiliar na resolução de tarefas maiores. O que distingue essas tarefas de outras tarefas potenciais e reais de PLN não é apenas o volume de pesquisa dedicado a elas, mas o fato de que para cada uma há tipicamente uma definição de problema bem especificada, uma métrica padrão para avaliar a tarefa, corpora padrão em que a tarefa pode ser avaliada e as competições dedicadas à tarefa específica.\\n• Em 1983, iniciou-se o Projecto Esprit P26, que avaliou as Tecnologias da Fala (incluindo tópicos gerais como Sintaxe e Semântica) comparando as abordagens baseadas em regras com as estatísticas. 12\\n• Em 1987, a primeira campanha de avaliação de textos escritos parece ser uma campanha dedicada à compreensão da mensagem (Pallet, 1998).\\n• Houve uma série de campanhas no projeto Tipster sobre tarefas como resumo, tradução e pesquisa (Hirschman 1998).\\n• Em 1996, a campanha Sparkle comparou os analisadores sintáticos em quatro idiomas diferentes (inglês, francês, alemão e italiano).\\n• Na França, o projeto Grace comparou um conjunto de 21 marcadores para o francês em 1997 (Adda 1999).\\n• Em 2004, durante o projeto Technolangue / Easy, foram comparados 13 analisadores para o francês.\\n• A avaliação em larga escala dos analisadores de dependência foi realizada no contexto das tarefas compartilhadas do CoNLL em 2006 e 2007.\\n• Em Itália, a campanha EVALITA foi realizada em 2007, 13 2009, 2011 e 2014 14 para comparar várias ferramentas de PLN e de voz para o site italiano - EVALITA.\\n\\nA avaliação intrínseca considera um sistema PNL isolado e caracteriza seu desempenho em relação a um resultado padrão-excelência, conforme definido pelos avaliadores. A avaliação extrínseca, também chamada de avaliação em uso, considera o sistema PLN em um cenário mais complexo como um sistema embutido ou uma função precisa para um usuário humano. O desempenho extrínseco do sistema é então caracterizado em termos de utilidade em relação à tarefa global do sistema estranho ou do utilizador humano. Por exemplo, considere um analisador sintático que é baseado na saída de alguma parte do tagger de fala (POS). Uma avaliação intrínseca executaria o marcador POS em dados estruturados e compararia a saída do sistema do marcador POS com a saída padrão ouro. Uma avaliação extrínseca executaria o analisador com algum outro marcador POS e, em seguida, com o marcador POS novo e compara a precisão de análise.\\n\\nA avaliação em caixa preta requer que alguém execute um sistema PLN em um conjunto de dados de amostra e para medir uma série de parâmetros relacionados com a qualidade do processo, como velocidade, confiabilidade, consumo de recursos e, principalmente, a qualidade do resultado, como a precisão da anotação de dados ou a fidelidade de uma tradução. A avaliação da caixa de vidro examina a concepção do sistema; Os algoritmos que são implementados, os recursos linguísticos que utiliza, como o tamanho do vocabulário ou a expressão definida de cardinalidade. Dada a complexidade dos problemas da PLN, muitas vezes é difícil prever o desempenho apenas com base na avaliação da caixa de vidro; Mas este tipo de avaliação é mais informativo no que diz respeito à análise de erros ou desenvolvimentos futuros de um sistema.\\n\\nEm muitos casos, procedimentos automáticos podem ser definidos para avaliar um sistema de PLN, comparando sua saída com o padrão de excelência. Embora o custo de reproduzir o padrão de excelência possa ser bastante elevado, avaliação automática de bootstrapping sobre os mesmos dados de entrada pode ser repetida quantas vezes for necessário sem custos adicionais desordenados. No entanto, para muitos problemas de PLN a definição precisa de um padrão de excelência é uma tarefa complexa e pode se revelar impossível quando o acordo inter-anotador é insuficiente. A avaliação manual é melhor realizada por juízes humanos instruídos para estimar a qualidade de um sistema, ou mais frequentemente de uma amostra de sua produção, com base em uma série de critérios. Embora, graças à sua competência linguística, os juízes humanos possam ser considerados como a referência para uma série de tarefas de processamento de linguagem, há também uma variação considerável em suas classificações. É por isso que a avaliação automática é, por vezes, referida como avaliação objetiva enquanto a avaliação humana é perspectiva.\\n\\nUm subcomitê ISO está trabalhando para facilitar a interoperabilidade entre recursos lexicais e programas PLN. O subcomitê faz parte do ISO / TC37 e é chamado ISO / TC37 / SC4. Alguns padrões ISO já estão publicados, mas a maioria deles está em construção, principalmente na representação de léxico (ver LMF), anotação e registro de categoria de dados.',\n",
              " 'domain': 'pt.wikipedia.org',\n",
              " 'image': None,\n",
              " 'links': ['/wiki/Wikip%C3%A9dia:Reciclagem',\n",
              "  '/wiki/Wikip%C3%A9dia:Reciclagem',\n",
              "  '/wiki/Wikip%C3%A9dia:Livro_de_estilo',\n",
              "  '/wiki/Wikip%C3%A9dia:Livro_de_estilo/Como_escrever_um_bom_artigo',\n",
              "  '/wiki/Ficheiro:Question_book-new.svg',\n",
              "  'https://www.google.com/search?as_eq=wikipedia&as_epq=Processamento+de+linguagem+natural',\n",
              "  'https://www.google.com/search?hl=pt&tbm=nws&q=Processamento+de+linguagem+natural&oq=Processamento+de+linguagem+natural',\n",
              "  'http://books.google.com/books?&as_brr=0&as_epq=Processamento+de+linguagem+natural',\n",
              "  'https://scholar.google.com.br/scholar?hl=pt&q=Processamento+de+linguagem+natural',\n",
              "  '/wiki/Wikip%C3%A9dia:Livro_de_estilo/Refer%C3%AAncias_e_notas_de_rodap%C3%A9',\n",
              "  '/wiki/Wikip%C3%A9dia:Verificabilidade',\n",
              "  '/wiki/Wikip%C3%A9dia:Verificabilidade#Política_de_verificabilidade',\n",
              "  '/wiki/Wikip%C3%A9dia:Livro_de_estilo/Cite_as_fontes',\n",
              "  '/wiki/Ficheiro:Automated_online_assistant.png',\n",
              "  '/wiki/Ficheiro:Automated_online_assistant.png',\n",
              "  '#cite_note-1',\n",
              "  '/wiki/Ci%C3%AAncia_da_computa%C3%A7%C3%A3o',\n",
              "  '/wiki/Intelig%C3%AAncia_artificial',\n",
              "  '/wiki/Lingu%C3%ADstica',\n",
              "  '/wiki/L%C3%ADnguas_naturais',\n",
              "  '/wiki/Bancos_de_dados',\n",
              "  '/wiki/Programa_de_computador',\n",
              "  '#História',\n",
              "  '#Usando_a_aprendizagem_automática_(aprendizado_de_máquina)',\n",
              "  '#Aplicações_principais',\n",
              "  '#Estatística',\n",
              "  '#Avaliação',\n",
              "  '#Cronologia_da_avaliação',\n",
              "  '#Diferentes_tipos_de_avaliação',\n",
              "  '#Padronização',\n",
              "  '#Ferramentas',\n",
              "  '#Veja_também',\n",
              "  '#Referências',\n",
              "  '#Leitura_adicional',\n",
              "  '/w/index.php?title=Processamento_de_linguagem_natural&veaction=edit&section=1',\n",
              "  '/w/index.php?title=Processamento_de_linguagem_natural&action=edit&section=1',\n",
              "  '/wiki/Teste_de_Turing',\n",
              "  'https://en.wikipedia.org/wiki/Georgetown%E2%80%93IBM_experiment',\n",
              "  '/wiki/Tradu%C3%A7%C3%A3o_autom%C3%A1tica',\n",
              "  '#cite_note-2',\n",
              "  'https://en.wikipedia.org/wiki/ALPAC',\n",
              "  'https://en.wikipedia.org/wiki/Statistical_machine_translation',\n",
              "  'https://en.wikipedia.org/wiki/SHRDLU',\n",
              "  'https://en.wikipedia.org/wiki/Blocks_world',\n",
              "  'https://en.wikipedia.org/wiki/Chatterbot',\n",
              "  '/wiki/Aprendizado_de_m%C3%A1quina',\n",
              "  '/wiki/Lei_de_Moore',\n",
              "  '/wiki/Noam_Chomsky',\n",
              "  '/wiki/Gram%C3%A1tica_gerativa',\n",
              "  '/wiki/Corpus_lingu%C3%ADstico',\n",
              "  '#cite_note-3',\n",
              "  '/wiki/%C3%81rvore_de_decis%C3%A3o',\n",
              "  'https://en.wikipedia.org/wiki/Part-of-speech_tagging',\n",
              "  '/wiki/Modelo_oculto_de_Markov',\n",
              "  'https://en.wikipedia.org/wiki/Stochastic_grammar',\n",
              "  'https://en.wikipedia.org/wiki/Cache_language_model',\n",
              "  'https://en.wikipedia.org/wiki/Parliament_of_Canada',\n",
              "  'https://en.wikipedia.org/wiki/European_Union',\n",
              "  'https://en.wikipedia.org/wiki/Semi-supervised_learning',\n",
              "  'https://en.wikipedia.org/wiki/Unsupervised_learning',\n",
              "  'https://en.wikipedia.org/wiki/Supervised_learning',\n",
              "  '/wiki/World_Wide_Web',\n",
              "  '/w/index.php?title=Processamento_de_linguagem_natural&veaction=edit&section=2',\n",
              "  '/w/index.php?title=Processamento_de_linguagem_natural&action=edit&section=2',\n",
              "  '/wiki/Infer%C3%AAncia_estat%C3%ADstica',\n",
              "  '/wiki/Aprendizado_de_m%C3%A1quina',\n",
              "  '/wiki/Corpus_lingu%C3%ADstico',\n",
              "  '/wiki/%C3%81rvore_de_decis%C3%A3o',\n",
              "  'https://en.wikipedia.org/wiki/Stochastic_grammar',\n",
              "  '/wiki/Probabilidade',\n",
              "  '#cite_note-4',\n",
              "  '#cite_note-5',\n",
              "  'https://en.wikipedia.org/wiki/Association_for_Computational_Linguistics',\n",
              "  '/wiki/Lingu%C3%ADstica_computacional',\n",
              "  '/wiki/Aquisi%C3%A7%C3%A3o_da_linguagem',\n",
              "  '/w/index.php?title=Processamento_de_linguagem_natural&veaction=edit&section=3',\n",
              "  '/w/index.php?title=Processamento_de_linguagem_natural&action=edit&section=3',\n",
              "  'https://en.wikipedia.org/wiki/Automatic_summarization',\n",
              "  'https://en.wikipedia.org/wiki/Coreference',\n",
              "  '/wiki/An%C3%A1fora_(lingu%C3%ADstica)',\n",
              "  '/wiki/Pronome',\n",
              "  '/wiki/An%C3%A1lise_sint%C3%A1tica_(computa%C3%A7%C3%A3o)',\n",
              "  '/wiki/Tradu%C3%A7%C3%A3o_autom%C3%A1tica',\n",
              "  'https://en.wikipedia.org/wiki/AI-complete',\n",
              "  '/wiki/Morfologia_(lingu%C3%ADstica)',\n",
              "  'https://en.wikipedia.org/wiki/Morpheme',\n",
              "  '/wiki/L%C3%ADngua_inglesa',\n",
              "  '/wiki/Flex%C3%A3o_(lingu%C3%ADstica)',\n",
              "  '/wiki/L%C3%ADngua_turca',\n",
              "  '/wiki/L%C3%ADngua_manipuri',\n",
              "  '/wiki/Aglutina%C3%A7%C3%A3o',\n",
              "  '#cite_note-6',\n",
              "  '/wiki/Reconhecimento_de_entidade_mencionada',\n",
              "  'https://en.wikipedia.org/wiki/Natural_language_understanding',\n",
              "  '/wiki/L%C3%B3gica_de_primeira_ordem',\n",
              "  'https://en.wikipedia.org/wiki/Closed-world_assumption',\n",
              "  'https://en.wikipedia.org/wiki/Open-world_assumption',\n",
              "  '#cite_note-7',\n",
              "  '/wiki/Reconhecimento_%C3%B3tico_de_caracteres',\n",
              "  'https://en.wikipedia.org/wiki/Part-of-speech_tagging',\n",
              "  '/wiki/Classe_gramatical',\n",
              "  '/wiki/L%C3%ADngua_tonal',\n",
              "  '/wiki/An%C3%A1lise_sint%C3%A1tica_(computa%C3%A7%C3%A3o)',\n",
              "  'https://en.wikipedia.org/wiki/Question_answering',\n",
              "  '#cite_note-8',\n",
              "  'https://en.wikipedia.org/wiki/Relationship_extraction',\n",
              "  'https://en.wikipedia.org/wiki/Sentence_boundary_disambiguation',\n",
              "  'https://en.wikipedia.org/wiki/Sentiment_analysis',\n",
              "  '/wiki/Reconhecimento_de_fala',\n",
              "  '/wiki/S%C3%ADntese_de_fala',\n",
              "  'https://en.wikipedia.org/wiki/Speech_segmentation',\n",
              "  'https://en.wikipedia.org/wiki/Speech_segmentation',\n",
              "  '/wiki/An%C3%A1lise_morfol%C3%B3gica',\n",
              "  'https://en.wikipedia.org/wiki/Text_segmentation',\n",
              "  '/wiki/An%C3%A1lise_morfol%C3%B3gica',\n",
              "  'https://en.wikipedia.org/wiki/Text_segmentation#Word_segmentation',\n",
              "  '/wiki/Desambigua%C3%A7%C3%A3o',\n",
              "  '/wiki/Recupera%C3%A7%C3%A3o_de_informa%C3%A7%C3%A3o',\n",
              "  'https://en.wikipedia.org/wiki/Information_extraction',\n",
              "  'https://en.wikipedia.org/wiki/Speech_processing',\n",
              "  'https://en.wikipedia.org/wiki/Native-language_identification',\n",
              "  '/wiki/Stemiza%C3%A7%C3%A3o',\n",
              "  'https://en.wikipedia.org/wiki/Text_simplification',\n",
              "  '/wiki/S%C3%ADntese_de_fala',\n",
              "  '/wiki/Revis%C3%A3o_de_texto',\n",
              "  'https://en.wikipedia.org/wiki/Natural_language_user_interface',\n",
              "  'https://en.wikipedia.org/wiki/Query_expansion',\n",
              "  'https://en.wikipedia.org/wiki/Automated_essay_scoring',\n",
              "  'https://en.wikipedia.org/wiki/Truecasing',\n",
              "  '/w/index.php?title=Processamento_de_linguagem_natural&veaction=edit&section=4',\n",
              "  '/w/index.php?title=Processamento_de_linguagem_natural&action=edit&section=4',\n",
              "  'https://en.wikipedia.org/wiki/Stochastic_grammar',\n",
              "  'https://en.wikipedia.org/wiki/Stochastic',\n",
              "  '/wiki/Probabilidade',\n",
              "  '/wiki/Estat%C3%ADstica',\n",
              "  '/wiki/Lingu%C3%ADstica_de_corpus',\n",
              "  'https://en.wikipedia.org/wiki/Markov_model',\n",
              "  'https://en.wikipedia.org/wiki/CSELT',\n",
              "  '#cite_note-9',\n",
              "  'https://en.wikipedia.org/wiki/Roberto_Pieraccini',\n",
              "  'https://en.wikipedia.org/wiki/Bell_Labs',\n",
              "  '#cite_note-10',\n",
              "  '/wiki/Teoria_da_informa%C3%A7%C3%A3o',\n",
              "  '/wiki/%C3%81lgebra_linear',\n",
              "  '#cite_note-11',\n",
              "  '/wiki/Aprendizado_de_m%C3%A1quina',\n",
              "  '/wiki/Minera%C3%A7%C3%A3o_de_dados',\n",
              "  '/wiki/Intelig%C3%AAncia_artificial',\n",
              "  '/w/index.php?title=Processamento_de_linguagem_natural&veaction=edit&section=5',\n",
              "  '/w/index.php?title=Processamento_de_linguagem_natural&action=edit&section=5',\n",
              "  '/w/index.php?title=Processamento_de_linguagem_natural&veaction=edit&section=6',\n",
              "  '/w/index.php?title=Processamento_de_linguagem_natural&action=edit&section=6',\n",
              "  '#cite_note-12',\n",
              "  'https://en.wikipedia.org/wiki/Technolangue/Easy',\n",
              "  '#cite_note-13',\n",
              "  '#cite_note-14',\n",
              "  'http://www.evalita.it/',\n",
              "  '/w/index.php?title=Processamento_de_linguagem_natural&veaction=edit&section=7',\n",
              "  '/w/index.php?title=Processamento_de_linguagem_natural&action=edit&section=7',\n",
              "  '/w/index.php?title=Processamento_de_linguagem_natural&veaction=edit&section=8',\n",
              "  '/w/index.php?title=Processamento_de_linguagem_natural&action=edit&section=8',\n",
              "  'https://en.wikipedia.org/wiki/Lexical_resource',\n",
              "  'https://en.wikipedia.org/wiki/ISO/TC_37',\n",
              "  'https://en.wikipedia.org/wiki/Lexical_Markup_Framework',\n",
              "  '/w/index.php?title=Processamento_de_linguagem_natural&veaction=edit&section=9',\n",
              "  '/w/index.php?title=Processamento_de_linguagem_natural&action=edit&section=9',\n",
              "  '/w/index.php?title=Expert_System_S.p.A.&action=edit&redlink=1',\n",
              "  '/w/index.php?title=General_Architecture_for_Text_Engineering&action=edit&redlink=1',\n",
              "  '/wiki/Modular_Audio_Recognition_Framework',\n",
              "  '/w/index.php?title=Natural_Language_Toolkit&action=edit&redlink=1',\n",
              "  '/w/index.php?title=Python_(programming_language)&action=edit&redlink=1',\n",
              "  '/w/index.php?title=OpenNLP&action=edit&redlink=1',\n",
              "  '/w/index.php?title=Processamento_de_linguagem_natural&veaction=edit&section=10',\n",
              "  '/w/index.php?title=Processamento_de_linguagem_natural&action=edit&section=10',\n",
              "  'https://en.wikipedia.org/wiki/Biomedical_text_mining',\n",
              "  'https://en.wikipedia.org/wiki/Compound_term_processing',\n",
              "  'https://en.wikipedia.org/wiki/Computer-assisted_reviewing',\n",
              "  '/wiki/L%C3%ADngua_natural_controlada',\n",
              "  'https://en.wikipedia.org/wiki/Deep_linguistic_processing',\n",
              "  'https://en.wikipedia.org/wiki/Computer-assisted_language_learning',\n",
              "  'https://en.wikipedia.org/wiki/Foreign_language_writing_aid',\n",
              "  'https://en.wikipedia.org/wiki/Computer-assisted_language_learning',\n",
              "  'https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation',\n",
              "  'https://en.wikipedia.org/wiki/Latent_semantic_analysis',\n",
              "  'https://en.wikipedia.org/wiki/Outline_of_natural_language_processing#Natural_language_processing_toolkits',\n",
              "  'https://en.wikipedia.org/wiki/LRE_Map',\n",
              "  'https://en.wikipedia.org/wiki/Natural_language_programming',\n",
              "  'https://en.wikipedia.org/wiki/Reification_(linguistics)',\n",
              "  'https://en.wikipedia.org/wiki/Semantic_folding',\n",
              "  'https://en.wikipedia.org/wiki/Spoken_dialog_systems',\n",
              "  'https://en.wikipedia.org/wiki/Thought_vector',\n",
              "  'https://en.wikipedia.org/wiki/Transderivational_search',\n",
              "  'https://en.wikipedia.org/wiki/Word2vec',\n",
              "  '#cite_ref-1',\n",
              "  '/wiki/Digital_object_identifier',\n",
              "  '//doi.org/10.1145/1643823.1643908',\n",
              "  'http://ahs.annaisd.org/common/pages/GalleryPhoto.aspx?photoId=11772950&width=180&height=180',\n",
              "  '/wiki/Especial:Fontes_de_livros/9781605588292',\n",
              "  '#cite_ref-2',\n",
              "  'http://ahs.annaisd.org/common/pages/GalleryPhoto.aspx?photoId=11772950&width=180&height=180',\n",
              "  '#cite_ref-3',\n",
              "  '/w/index.php?title=Corner_case&action=edit&redlink=1',\n",
              "  '/w/index.php?title=Pathological_(mathematics)&action=edit&redlink=1',\n",
              "  '/w/index.php?title=Thought_experiment&action=edit&redlink=1',\n",
              "  '/w/index.php?title=Corpus_linguistics&action=edit&redlink=1',\n",
              "  '/w/index.php?title=Text_corpus&action=edit&redlink=1',\n",
              "  '/w/index.php?title=Poverty_of_the_stimulus&action=edit&redlink=1',\n",
              "  '#cite_ref-4',\n",
              "  'http://www.signll.org/conll/',\n",
              "  '#cite_ref-5',\n",
              "  'http://www.signll.org/about/',\n",
              "  '#cite_ref-6',\n",
              "  'http://aclweb.org/anthology//W/W12/W12-5008.pdf',\n",
              "  '#cite_ref-7',\n",
              "  'http://www.ijimt.org/abstract/100-E00187.htm',\n",
              "  'https://web.archive.org/web/20111009135952/http://www.ijimt.org/abstract/100-E00187.htm',\n",
              "  '/wiki/Wayback_Machine',\n",
              "  '#cite_ref-8',\n",
              "  'https://www.academia.edu/2475776/Versatile_question_answering_systems_seeing_in_synthesis',\n",
              "  '#cite_ref-9',\n",
              "  '#cite_ref-10',\n",
              "  '#cite_ref-11',\n",
              "  '/wiki/MIT_Press',\n",
              "  '/wiki/Especial:Fontes_de_livros/9780262133609',\n",
              "  '#cite_ref-12',\n",
              "  '#cite_ref-13',\n",
              "  'http://www.lrec-conf.org/proceedings/lrec2008/pdf/630_paper.pdf',\n",
              "  '#cite_ref-14',\n",
              "  'http://content.iospress.com/articles/intelligenza-artificiale/ia076',\n",
              "  '/w/index.php?title=Processamento_de_linguagem_natural&veaction=edit&section=11',\n",
              "  '/w/index.php?title=Processamento_de_linguagem_natural&action=edit&section=11',\n",
              "  '/wiki/Especial:Fontes_de_livros/9780596516499',\n",
              "  '/wiki/Especial:Fontes_de_livros/9780131873216',\n",
              "  '/wiki/Especial:Fontes_de_livros/9780521865715',\n",
              "  'http://nlp.stanford.edu/IR-book/',\n",
              "  '/wiki/Especial:Fontes_de_livros/9780262133609',\n",
              "  '/wiki/Especial:Fontes_de_livros/9780387195575'],\n",
              " 'meta': {'canonical': 'https://pt.wikipedia.org/wiki/Processamento_de_linguagem_natural',\n",
              "  'description': '',\n",
              "  'encoding': 'UTF-8',\n",
              "  'favicon': '/static/apple-touch/wikipedia.png',\n",
              "  'keywords': '',\n",
              "  'lang': 'pt'},\n",
              " 'movies': [],\n",
              " 'opengraph': {'image': 'https://upload.wikimedia.org/wikipedia/commons/8/8b/Automated_online_assistant.png',\n",
              "  'image:height': '802',\n",
              "  'image:width': '640',\n",
              "  'title': 'Processamento de linguagem natural – Wikipédia, a enciclopédia livre',\n",
              "  'type': 'website'},\n",
              " 'publish_date': None,\n",
              " 'tags': [],\n",
              " 'title': 'Processamento de linguagem natural – Wikipédia, a enciclopédia livre',\n",
              " 'tweets': []}"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article.title\n",
        "article.cleaned_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "7WzN_962im7u",
        "outputId": "1efa6255-033d-42bb-94fa-353c5348c3d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Processamento de língua natural (PLN) é uma subárea da ciência da computação, inteligência artificial e da linguística que estuda os problemas da geração e compreensão automática de línguas humanas naturais. Sistemas de geração de língua natural convertem informação de bancos de dados de computadores em linguagem compreensível ao ser humano e sistemas de compreensão de língua natural convertem ocorrências de linguagem humana em representações mais formais, mais facilmente manipuláveis por programas de computador. Alguns desafios do PLN são compreensão de língua natural, fazer com que computadores extraiam sentido de linguagem humana ou natural e geração de língua natural.\\n\\nA história do PLN começou na década de 1950, quando Alan Turing publicou o artigo \"Computing Machinery and Intelligence\", que propunha o que agora é chamado de teste de Turing como critério de inteligência.\\n\\nEm 1954, a experiência de Georgetown envolveu a tradução automática de mais de sessenta frases russas para o inglês. Os autores afirmaram que dentro de três ou cinco anos a tradução automática seria um problema resolvido.[2] No entanto, os avanços reais foram muito mais lentos do que o previsto e, após o relatório ALPAC em 1966, que constatou que a pesquisa de dez anos não conseguiu satisfazer as expectativas, o financiamento para este estudo em tradução automática foi reduzido drasticamente. Poucas pesquisas em tradução automática foram conduzidas até o final dos anos 80, quando os primeiros sistemas estatísticos de tradução foram desenvolvidos.\\n\\nAlguns sistemas de PLN bem sucedidos desenvolvidos nos anos 60 foram SHRDLU, um sistema de língua natural que trabalhava em \"blocks worlds\" com vocabulário restrito e ELIZA, uma simulação de um psicoterapeuta escrita por Joseph Weizenbaum entre 1964 e 1966. Usando pouca informação sobre o pensamento ou a emoção humana, ELIZA criava, em alguns casos, interações surpreendentemente humanas. Quando o \"paciente\" excedia a base de conhecimento do programa, ELIZA fornecia uma resposta genérica, por exemplo, respondendo a \"Minha cabeça dói\" com \"Por que você diz que sua cabeça dói?\".\\n\\nDurante a década de 1970, muitos programadores começaram a escrever \"ontologias conceituais\", que estruturaram a informação do mundo real em dados compreensíveis por computadores. Exemplos são MARGIE (SCHANK, 1975), SAM (CULLINGFORD, 1978), PAM (WILENSKY, 1978), TaleSpin (MEEHAN, 1976), QUALM (LEHNERT, 1977), Politics (CARBONELL, 1979) e Plot Units (LEHNERT, 1981 ). Neste período, muitos chatterbots foram escritos, como PARRY, Racter e Jabberwacky.\\n\\nAté a década de 1980, a maioria dos sistemas de PLN se baseava em conjuntos complexos de regras manuscritas. A partir do final dos anos 1980, no entanto, houve uma revolução no PLN com a introdução de algoritmos de aprendizagem automática (aprendizado de máquina) para o processamento de linguagem. Isto foi devido tanto ao aumento constante do poder computacional (ver Lei de Moore) quanto à diminuição gradual da dominância das teorias da linguística chomskyanas (como a gramática gerativa), cujos fundamentos teóricos desestimularam o tipo de corpus linguístico que está subjacente à abordagem da aprendizagem automática ao processamento da linguagem[3].\\n\\nAlguns dos algoritmos de aprendizado de máquinas mais antigos, como as árvores de decisão, produziam sistemas de regras rígidas então semelhantes às regras existentes na escritas à mão. No entanto, a marcação de partes da fala (part-of-speech tagging) introduziu o uso de modelos ocultos de Markov para o PLN e, cada vez mais, a pesquisa se concentrava em modelos estatísticos, que tomam decisões suaves e probabilísticas baseadas na atribuição de pesos reais aos recursos que compõem dados de entrada. Os modelos de linguagem de cache, sobre os quais muitos sistemas de reconhecimento de fala agora dependem, são exemplos de tais modelos estatísticos. Esses modelos são geralmente mais robustos quando dados informações desconhecidas, especialmente entrada que contém erros (como é muito comum para dados do mundo real) e produzem resultados mais confiáveis quando integrados em sistemas maiores que compreendem múltiplas tarefas.\\n\\nMuitos dos sucessos iniciais notáveis ocorreram no campo da tradução automática, devido especialmente ao trabalho de pesquisa da IBM, que desenvolveu modelos estatísticos mais elaborados. Estes sistemas foram capazes de tirar proveito de corpora textuais multilíngues existentes produzidos pelo Parlamento do Canadá e a União Europeia como resultado de leis que exigem a tradução de todos os processos governamentais em todas as línguas oficiais dos países. No entanto, a maioria dos sistemas dependia de corpora desenvolvido especificamente para tarefas implementadas por esses sistemas, o que era (e muitas vezes continua sendo) uma grande limitação no sucesso dos mesmo. Como resultado, uma grande quantidade de pesquisa passou de quantidades de dados limitadas a métodos de aprendizagem mais eficazes.\\n\\nPesquisas recentes têm se concentrado cada vez mais em algoritmos de aprendizagem semi-supervisionados e sem supervisão. Esses algoritmos são capazes de aprender com dados que não foram anotados manualmente com as respostas desejadas ou usando uma combinação de dados anotados e não anotados. Geralmente, esta tarefa é muito mais trabalhosa do que a aprendizagem supervisionada e normalmente produz resultados menos precisos para uma quantidade específica de dados de entrada. No entanto, há uma enorme quantidade de dados não anotados disponíveis (incluindo, entre outras coisas, todo o conteúdo da World Wide Web), que muitas vezes pode compensar os resultados inferiores.\\n\\nOs algoritmos modernos de PLN baseiam-se na aprendizagem mecânica, especialmente na aprendizagem de máquinas estatísticas. O paradigma da aprendizagem mecânica é diferente do da maioria das tentativas anteriores de processamento da linguagem. Anteriormente, implementações de tarefas de processamento de linguagem envolviam a codificação direta de grandes conjuntos de regras. O paradigma da aprendizagem automática (ou aprendizagem automática) induz a aprendizagem automática de regras através de análises de corpora de exemplos típicos do mundo real ao invés de usar algoritmos gerais de aprendizagem (muitas vezes, embora nem sempre, baseados em inferência estatística). Um corpus (plural \"corpora\") é um conjunto de documentos (ou frases individuais) que foram anotados à mão com os valores corretos a serem aprendidos.\\n\\nMuitas classes diferentes de algoritmos de aprendizado de máquina foram aplicadas a tarefas de PLN. Esses algoritmos tomam como entrada um grande conjunto de \"recursos\" que são gerados a partir de dados de entrada.\\n\\nAlguns dos algoritmos mais usados, como árvores de decisão, produziam sistemas de regras rígidas semelhantes aos sistemas de regras manuscritas mais comuns. No entanto, cada vez mais, a pesquisa tem se concentrado em modelos estatísticos, que tomam decisões flexíveis e probabilísticas baseadas em agregar pesos reais a cada característica de entrada. Tais modelos têm a vantagem de poder expressar a certeza relativa de muitas respostas possíveis diferentes em vez de apenas uma, produzindo resultados mais confiáveis quando esse modelo é incluído como um componente de um sistema maior.\\n\\nOs sistemas baseados em algoritmos de aprendizagem mecânica têm muitas vantagens em relação às regras produzidas manualmente:\\n• Os procedimentos de aprendizagem usados durante a aprendizagem da máquina focam-se automaticamente nos casos mais comuns, ao passo que quando se escrevem regras à mão, não é óbvio em que sentido o esforço deve ser dirigido.\\n• Os procedimentos de aprendizagem automática podem fazer uso de algoritmos de inferência estatística para produzir modelos que são robustos a entradas não familiares (por exemplo, contendo palavras ou estruturas que não foram vistas antes) e a entradas errôneas (por exemplo, com palavras ou palavras incorretamente omitidas). Geralmente, lidar com essas entradas de forma com regras manuscritas ou sistemas de regras manuscritas que tomam decisões suaves é extremamente trabalhoso, propenso a erros e demorado.\\n• Sistemas baseados em aprender automaticamente as regras podem ser mais precisos simplesmente fornecendo mais dados de entrada. No entanto, os sistemas baseados em regras escritas à mão só podem ser tornados mais precisos aumentando a complexidade das regras, o que é uma tarefa muito mais difícil. Em particular, há um limite para a complexidade de sistemas baseados em regras artesanais, para além dos quais os sistemas se tornam cada vez mais incontroláveis. No entanto, a criação de mais dados para entrada em sistemas de aprendizado de máquina requer simplesmente um aumento correspondente no número de horas trabalhadas por humanos, geralmente sem aumentos significativos na complexidade do processo de anotação.\\n\\nO subcampo de PLN dedicado a abordagens de aprendizagem é conhecido como aprendizagem de língua natural (NLL) e sua conferência, a CoNLL,[4] e orgão central, o SIGNLL,[5] são patrocinados pela ACL, reconhecendo também as suas ligações com linguística computacional e aquisição de linguagem. Quando o objetivo da pesquisa de aprendizagem de linguagem computacional é entender mais sobre aquisição de linguagem humana, ou psicolinguística, a NLL sobrepõe-se no campo relacionado de psicolinguística computacional.\\n\\nA listagem a seguir traz alguns dos trabalhos mais pesquisadas em PLN. Note que alguns deles têm aplicações no mundo real, enquanto outras servem mais frequentemente como tarefas secundárias que são usadas para auxiliar na resolução de tarefas maiores. O que distingue essas tarefas de outras tarefas potenciais e reais de PLN não é apenas o volume de pesquisa dedicado a elas, mas o fato de que para cada uma há tipicamente uma definição de problema bem especificada, uma métrica padrão para avaliar a tarefa, corpora padrão em que a tarefa pode ser avaliada e as competições dedicadas à tarefa específica.\\n• Em 1983, iniciou-se o Projecto Esprit P26, que avaliou as Tecnologias da Fala (incluindo tópicos gerais como Sintaxe e Semântica) comparando as abordagens baseadas em regras com as estatísticas. 12\\n• Em 1987, a primeira campanha de avaliação de textos escritos parece ser uma campanha dedicada à compreensão da mensagem (Pallet, 1998).\\n• Houve uma série de campanhas no projeto Tipster sobre tarefas como resumo, tradução e pesquisa (Hirschman 1998).\\n• Em 1996, a campanha Sparkle comparou os analisadores sintáticos em quatro idiomas diferentes (inglês, francês, alemão e italiano).\\n• Na França, o projeto Grace comparou um conjunto de 21 marcadores para o francês em 1997 (Adda 1999).\\n• Em 2004, durante o projeto Technolangue / Easy, foram comparados 13 analisadores para o francês.\\n• A avaliação em larga escala dos analisadores de dependência foi realizada no contexto das tarefas compartilhadas do CoNLL em 2006 e 2007.\\n• Em Itália, a campanha EVALITA foi realizada em 2007, 13 2009, 2011 e 2014 14 para comparar várias ferramentas de PLN e de voz para o site italiano - EVALITA.\\n\\nA avaliação intrínseca considera um sistema PNL isolado e caracteriza seu desempenho em relação a um resultado padrão-excelência, conforme definido pelos avaliadores. A avaliação extrínseca, também chamada de avaliação em uso, considera o sistema PLN em um cenário mais complexo como um sistema embutido ou uma função precisa para um usuário humano. O desempenho extrínseco do sistema é então caracterizado em termos de utilidade em relação à tarefa global do sistema estranho ou do utilizador humano. Por exemplo, considere um analisador sintático que é baseado na saída de alguma parte do tagger de fala (POS). Uma avaliação intrínseca executaria o marcador POS em dados estruturados e compararia a saída do sistema do marcador POS com a saída padrão ouro. Uma avaliação extrínseca executaria o analisador com algum outro marcador POS e, em seguida, com o marcador POS novo e compara a precisão de análise.\\n\\nA avaliação em caixa preta requer que alguém execute um sistema PLN em um conjunto de dados de amostra e para medir uma série de parâmetros relacionados com a qualidade do processo, como velocidade, confiabilidade, consumo de recursos e, principalmente, a qualidade do resultado, como a precisão da anotação de dados ou a fidelidade de uma tradução. A avaliação da caixa de vidro examina a concepção do sistema; Os algoritmos que são implementados, os recursos linguísticos que utiliza, como o tamanho do vocabulário ou a expressão definida de cardinalidade. Dada a complexidade dos problemas da PLN, muitas vezes é difícil prever o desempenho apenas com base na avaliação da caixa de vidro; Mas este tipo de avaliação é mais informativo no que diz respeito à análise de erros ou desenvolvimentos futuros de um sistema.\\n\\nEm muitos casos, procedimentos automáticos podem ser definidos para avaliar um sistema de PLN, comparando sua saída com o padrão de excelência. Embora o custo de reproduzir o padrão de excelência possa ser bastante elevado, avaliação automática de bootstrapping sobre os mesmos dados de entrada pode ser repetida quantas vezes for necessário sem custos adicionais desordenados. No entanto, para muitos problemas de PLN a definição precisa de um padrão de excelência é uma tarefa complexa e pode se revelar impossível quando o acordo inter-anotador é insuficiente. A avaliação manual é melhor realizada por juízes humanos instruídos para estimar a qualidade de um sistema, ou mais frequentemente de uma amostra de sua produção, com base em uma série de critérios. Embora, graças à sua competência linguística, os juízes humanos possam ser considerados como a referência para uma série de tarefas de processamento de linguagem, há também uma variação considerável em suas classificações. É por isso que a avaliação automática é, por vezes, referida como avaliação objetiva enquanto a avaliação humana é perspectiva.\\n\\nUm subcomitê ISO está trabalhando para facilitar a interoperabilidade entre recursos lexicais e programas PLN. O subcomitê faz parte do ISO / TC37 e é chamado ISO / TC37 / SC4. Alguns padrões ISO já estão publicados, mas a maioria deles está em construção, principalmente na representação de léxico (ver LMF), anotação e registro de categoria de dados.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_summarization(article.cleaned_text,20,article.title)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nGnhEVpZiuez",
        "outputId": "0b4e9e36-50ee-4660-bff1-c91244c6dc8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<H1>Resumo Processamento de linguagem natural – Wikipédia, a enciclopédia livre </H1>Processamento de língua natural (PLN) é uma subárea da ciência da computação, inteligência artificial e da linguística que estuda os problemas da geração e compreensão automática de línguas humanas naturais.<mark>Sistemas de geração de língua natural convertem informação de bancos de dados de computadores em linguagem compreensível ao ser humano e sistemas de compreensão de língua natural convertem ocorrências de linguagem humana em representações mais formais, mais facilmente manipuláveis por programas de computador.</mark><mark>Alguns desafios do PLN são compreensão de língua natural, fazer com que computadores extraiam sentido de linguagem humana ou natural e geração de língua natural.</mark>A história do PLN começou na década de 1950, quando Alan Turing publicou o artigo \"Computing Machinery and Intelligence\", que propunha o que agora é chamado de teste de Turing como critério de inteligência.Em 1954, a experiência de Georgetown envolveu a tradução automática de mais de sessenta frases russas para o inglês.Os autores afirmaram que dentro de três ou cinco anos a tradução automática seria um problema resolvido.[2] No entanto, os avanços reais foram muito mais lentos do que o previsto e, após o relatório ALPAC em 1966, que constatou que a pesquisa de dez anos não conseguiu satisfazer as expectativas, o financiamento para este estudo em tradução automática foi reduzido drasticamente.Poucas pesquisas em tradução automática foram conduzidas até o final dos anos 80, quando os primeiros sistemas estatísticos de tradução foram desenvolvidos.<mark>Alguns sistemas de PLN bem sucedidos desenvolvidos nos anos 60 foram SHRDLU, um sistema de língua natural que trabalhava em \"blocks worlds\" com vocabulário restrito e ELIZA, uma simulação de um psicoterapeuta escrita por Joseph Weizenbaum entre 1964 e 1966.</mark>Usando pouca informação sobre o pensamento ou a emoção humana, ELIZA criava, em alguns casos, interações surpreendentemente humanas.Quando o \"paciente\" excedia a base de conhecimento do programa, ELIZA fornecia uma resposta genérica, por exemplo, respondendo a \"Minha cabeça dói\" com \"Por que você diz que sua cabeça dói?\".Durante a década de 1970, muitos programadores começaram a escrever \"ontologias conceituais\", que estruturaram a informação do mundo real em dados compreensíveis por computadores.Exemplos são MARGIE (SCHANK, 1975), SAM (CULLINGFORD, 1978), PAM (WILENSKY, 1978), TaleSpin (MEEHAN, 1976), QUALM (LEHNERT, 1977), Politics (CARBONELL, 1979) e Plot Units (LEHNERT, 1981 ).Neste período, muitos chatterbots foram escritos, como PARRY, Racter e Jabberwacky.Até a década de 1980, a maioria dos sistemas de PLN se baseava em conjuntos complexos de regras manuscritas.<mark>A partir do final dos anos 1980, no entanto, houve uma revolução no PLN com a introdução de algoritmos de aprendizagem automática (aprendizado de máquina) para o processamento de linguagem.</mark>Isto foi devido tanto ao aumento constante do poder computacional (ver Lei de Moore) quanto à diminuição gradual da dominância das teorias da linguística chomskyanas (como a gramática gerativa), cujos fundamentos teóricos desestimularam o tipo de corpus linguístico que está subjacente à abordagem da aprendizagem automática ao processamento da linguagem[3].<mark>Alguns dos algoritmos de aprendizado de máquinas mais antigos, como as árvores de decisão, produziam sistemas de regras rígidas então semelhantes às regras existentes na escritas à mão.</mark><mark>No entanto, a marcação de partes da fala (part-of-speech tagging) introduziu o uso de modelos ocultos de Markov para o PLN e, cada vez mais, a pesquisa se concentrava em modelos estatísticos, que tomam decisões suaves e probabilísticas baseadas na atribuição de pesos reais aos recursos que compõem dados de entrada.</mark>Os modelos de linguagem de cache, sobre os quais muitos sistemas de reconhecimento de fala agora dependem, são exemplos de tais modelos estatísticos.<mark>Esses modelos são geralmente mais robustos quando dados informações desconhecidas, especialmente entrada que contém erros (como é muito comum para dados do mundo real) e produzem resultados mais confiáveis quando integrados em sistemas maiores que compreendem múltiplas tarefas.</mark>Muitos dos sucessos iniciais notáveis ocorreram no campo da tradução automática, devido especialmente ao trabalho de pesquisa da IBM, que desenvolveu modelos estatísticos mais elaborados.Estes sistemas foram capazes de tirar proveito de corpora textuais multilíngues existentes produzidos pelo Parlamento do Canadá e a União Europeia como resultado de leis que exigem a tradução de todos os processos governamentais em todas as línguas oficiais dos países.<mark>No entanto, a maioria dos sistemas dependia de corpora desenvolvido especificamente para tarefas implementadas por esses sistemas, o que era (e muitas vezes continua sendo) uma grande limitação no sucesso dos mesmo.</mark>Como resultado, uma grande quantidade de pesquisa passou de quantidades de dados limitadas a métodos de aprendizagem mais eficazes.Pesquisas recentes têm se concentrado cada vez mais em algoritmos de aprendizagem semi-supervisionados e sem supervisão.Esses algoritmos são capazes de aprender com dados que não foram anotados manualmente com as respostas desejadas ou usando uma combinação de dados anotados e não anotados.Geralmente, esta tarefa é muito mais trabalhosa do que a aprendizagem supervisionada e normalmente produz resultados menos precisos para uma quantidade específica de dados de entrada.No entanto, há uma enorme quantidade de dados não anotados disponíveis (incluindo, entre outras coisas, todo o conteúdo da World Wide Web), que muitas vezes pode compensar os resultados inferiores.Os algoritmos modernos de PLN baseiam-se na aprendizagem mecânica, especialmente na aprendizagem de máquinas estatísticas.O paradigma da aprendizagem mecânica é diferente do da maioria das tentativas anteriores de processamento da linguagem.Anteriormente, implementações de tarefas de processamento de linguagem envolviam a codificação direta de grandes conjuntos de regras.<mark>O paradigma da aprendizagem automática (ou aprendizagem automática) induz a aprendizagem automática de regras através de análises de corpora de exemplos típicos do mundo real ao invés de usar algoritmos gerais de aprendizagem (muitas vezes, embora nem sempre, baseados em inferência estatística).</mark>Um corpus (plural \"corpora\") é um conjunto de documentos (ou frases individuais) que foram anotados à mão com os valores corretos a serem aprendidos.Muitas classes diferentes de algoritmos de aprendizado de máquina foram aplicadas a tarefas de PLN.Esses algoritmos tomam como entrada um grande conjunto de \"recursos\" que são gerados a partir de dados de entrada.<mark>Alguns dos algoritmos mais usados, como árvores de decisão, produziam sistemas de regras rígidas semelhantes aos sistemas de regras manuscritas mais comuns.</mark>No entanto, cada vez mais, a pesquisa tem se concentrado em modelos estatísticos, que tomam decisões flexíveis e probabilísticas baseadas em agregar pesos reais a cada característica de entrada.Tais modelos têm a vantagem de poder expressar a certeza relativa de muitas respostas possíveis diferentes em vez de apenas uma, produzindo resultados mais confiáveis quando esse modelo é incluído como um componente de um sistema maior.<mark>Os sistemas baseados em algoritmos de aprendizagem mecânica têm muitas vantagens em relação às regras produzidas manualmente:\n",
              "• Os procedimentos de aprendizagem usados durante a aprendizagem da máquina focam-se automaticamente nos casos mais comuns, ao passo que quando se escrevem regras à mão, não é óbvio em que sentido o esforço deve ser dirigido.</mark><mark>• Os procedimentos de aprendizagem automática podem fazer uso de algoritmos de inferência estatística para produzir modelos que são robustos a entradas não familiares (por exemplo, contendo palavras ou estruturas que não foram vistas antes) e a entradas errôneas (por exemplo, com palavras ou palavras incorretamente omitidas).</mark>Geralmente, lidar com essas entradas de forma com regras manuscritas ou sistemas de regras manuscritas que tomam decisões suaves é extremamente trabalhoso, propenso a erros e demorado.<mark>• Sistemas baseados em aprender automaticamente as regras podem ser mais precisos simplesmente fornecendo mais dados de entrada.</mark><mark>No entanto, os sistemas baseados em regras escritas à mão só podem ser tornados mais precisos aumentando a complexidade das regras, o que é uma tarefa muito mais difícil.</mark>Em particular, há um limite para a complexidade de sistemas baseados em regras artesanais, para além dos quais os sistemas se tornam cada vez mais incontroláveis.No entanto, a criação de mais dados para entrada em sistemas de aprendizado de máquina requer simplesmente um aumento correspondente no número de horas trabalhadas por humanos, geralmente sem aumentos significativos na complexidade do processo de anotação.<mark>O subcampo de PLN dedicado a abordagens de aprendizagem é conhecido como aprendizagem de língua natural (NLL) e sua conferência, a CoNLL,[4] e orgão central, o SIGNLL,[5] são patrocinados pela ACL, reconhecendo também as suas ligações com linguística computacional e aquisição de linguagem.</mark>Quando o objetivo da pesquisa de aprendizagem de linguagem computacional é entender mais sobre aquisição de linguagem humana, ou psicolinguística, a NLL sobrepõe-se no campo relacionado de psicolinguística computacional.A listagem a seguir traz alguns dos trabalhos mais pesquisadas em PLN.Note que alguns deles têm aplicações no mundo real, enquanto outras servem mais frequentemente como tarefas secundárias que são usadas para auxiliar na resolução de tarefas maiores.<mark>O que distingue essas tarefas de outras tarefas potenciais e reais de PLN não é apenas o volume de pesquisa dedicado a elas, mas o fato de que para cada uma há tipicamente uma definição de problema bem especificada, uma métrica padrão para avaliar a tarefa, corpora padrão em que a tarefa pode ser avaliada e as competições dedicadas à tarefa específica.</mark>• Em 1983, iniciou-se o Projecto Esprit P26, que avaliou as Tecnologias da Fala (incluindo tópicos gerais como Sintaxe e Semântica) comparando as abordagens baseadas em regras com as estatísticas.12\n",
              "• Em 1987, a primeira campanha de avaliação de textos escritos parece ser uma campanha dedicada à compreensão da mensagem (Pallet, 1998).• Houve uma série de campanhas no projeto Tipster sobre tarefas como resumo, tradução e pesquisa (Hirschman 1998).• Em 1996, a campanha Sparkle comparou os analisadores sintáticos em quatro idiomas diferentes (inglês, francês, alemão e italiano).• Na França, o projeto Grace comparou um conjunto de 21 marcadores para o francês em 1997 (Adda 1999).• Em 2004, durante o projeto Technolangue / Easy, foram comparados 13 analisadores para o francês.• A avaliação em larga escala dos analisadores de dependência foi realizada no contexto das tarefas compartilhadas do CoNLL em 2006 e 2007.• Em Itália, a campanha EVALITA foi realizada em 2007, 13 2009, 2011 e 2014 14 para comparar várias ferramentas de PLN e de voz para o site italiano - EVALITA.A avaliação intrínseca considera um sistema PNL isolado e caracteriza seu desempenho em relação a um resultado padrão-excelência, conforme definido pelos avaliadores.<mark>A avaliação extrínseca, também chamada de avaliação em uso, considera o sistema PLN em um cenário mais complexo como um sistema embutido ou uma função precisa para um usuário humano.</mark>O desempenho extrínseco do sistema é então caracterizado em termos de utilidade em relação à tarefa global do sistema estranho ou do utilizador humano.Por exemplo, considere um analisador sintático que é baseado na saída de alguma parte do tagger de fala (POS).Uma avaliação intrínseca executaria o marcador POS em dados estruturados e compararia a saída do sistema do marcador POS com a saída padrão ouro.Uma avaliação extrínseca executaria o analisador com algum outro marcador POS e, em seguida, com o marcador POS novo e compara a precisão de análise.<mark>A avaliação em caixa preta requer que alguém execute um sistema PLN em um conjunto de dados de amostra e para medir uma série de parâmetros relacionados com a qualidade do processo, como velocidade, confiabilidade, consumo de recursos e, principalmente, a qualidade do resultado, como a precisão da anotação de dados ou a fidelidade de uma tradução.</mark>A avaliação da caixa de vidro examina a concepção do sistema; Os algoritmos que são implementados, os recursos linguísticos que utiliza, como o tamanho do vocabulário ou a expressão definida de cardinalidade.<mark>Dada a complexidade dos problemas da PLN, muitas vezes é difícil prever o desempenho apenas com base na avaliação da caixa de vidro; Mas este tipo de avaliação é mais informativo no que diz respeito à análise de erros ou desenvolvimentos futuros de um sistema.</mark>Em muitos casos, procedimentos automáticos podem ser definidos para avaliar um sistema de PLN, comparando sua saída com o padrão de excelência.<mark>Embora o custo de reproduzir o padrão de excelência possa ser bastante elevado, avaliação automática de bootstrapping sobre os mesmos dados de entrada pode ser repetida quantas vezes for necessário sem custos adicionais desordenados.</mark>No entanto, para muitos problemas de PLN a definição precisa de um padrão de excelência é uma tarefa complexa e pode se revelar impossível quando o acordo inter-anotador é insuficiente.A avaliação manual é melhor realizada por juízes humanos instruídos para estimar a qualidade de um sistema, ou mais frequentemente de uma amostra de sua produção, com base em uma série de critérios.Embora, graças à sua competência linguística, os juízes humanos possam ser considerados como a referência para uma série de tarefas de processamento de linguagem, há também uma variação considerável em suas classificações.É por isso que a avaliação automática é, por vezes, referida como avaliação objetiva enquanto a avaliação humana é perspectiva.Um subcomitê ISO está trabalhando para facilitar a interoperabilidade entre recursos lexicais e programas PLN.O subcomitê faz parte do ISO / TC37 e é chamado ISO / TC37 / SC4.Alguns padrões ISO já estão publicados, mas a maioria deles está em construção, principalmente na representação de léxico (ver LMF), anotação e registro de categoria de dados."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step by Step"
      ],
      "metadata": {
        "id": "5InYtC-2XxOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processed_text = pre_process(text_base)\n",
        "processed_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "Nsain7fp9RHf",
        "outputId": "4f89cb37-3f90-41e3-f180-9e5e76cc62b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"processamento língua natural pln subárea ciência computação inteligência artificial linguística estuda problemas geração compreensão automática línguas humanas naturais sistemas geração língua natural convertem informação bancos dados computadores linguagem compreensível ser humano sistemas compreensão língua natural convertem ocorrências linguagem humana representações formais facilmente manipuláveis programas computador alguns desafios pln compreensão língua natural fazer computadores extraiam sentido linguagem humana natural geração língua natural história pln começou década 1950 alan turing publicou artigo `` computing machinery and intelligence '' propunha agora chamado teste turing critério inteligência 1954 experiência georgetown envolveu tradução automática sessenta frases russas inglês autores afirmaram dentro três cinco anos tradução automática problema resolvido 2 entanto avanços reais lentos previsto após relatório alpac 1966 constatou pesquisa dez anos conseguiu satisfazer expectativas financiamento estudo tradução automática reduzido drasticamente poucas pesquisas tradução automática conduzidas final anos 80 primeiros sistemas estatísticos tradução desenvolvidos alguns sistemas pln bem sucedidos desenvolvidos anos 60 shrdlu sistema língua natural trabalhava `` blocks worlds '' vocabulário restrito eliza simulação psicoterapeuta escrita joseph weizenbaum 1964 1966. usando pouca informação sobre pensamento emoção humana eliza criava alguns casos interações surpreendentemente humanas `` paciente '' excedia base conhecimento programa eliza fornecia resposta genérica exemplo respondendo `` cabeça dói '' `` diz cabeça dói '' durante década 1970 muitos programadores começaram escrever `` ontologias conceituais '' estruturaram informação mundo real dados compreensíveis computadores exemplos margie schank 1975 sam cullingford 1978 pam wilensky 1978 talespin meehan 1976 qualm lehnert 1977 politics carbonell 1979 plot units lehnert 1981 neste período muitos chatterbots escritos parry racter jabberwacky década 1980 maioria sistemas pln baseava conjuntos complexos regras manuscritas partir final anos 1980 entanto revolução pln introdução algoritmos aprendizagem automática aprendizado máquina processamento linguagem devido tanto aumento constante poder computacional ver lei moore quanto diminuição gradual dominância teorias linguística chomskyanas gramática gerativa cujos fundamentos teóricos desestimularam tipo corpus linguístico subjacente abordagem aprendizagem automática processamento linguagem 3 alguns algoritmos aprendizado máquinas antigos árvores decisão produziam sistemas regras rígidas então semelhantes regras existentes escritas mão entanto marcação partes fala part-of-speech tagging introduziu uso modelos ocultos markov pln cada vez pesquisa concentrava modelos estatísticos tomam decisões suaves probabilísticas baseadas atribuição pesos reais recursos compõem dados entrada modelos linguagem cache sobre quais muitos sistemas reconhecimento fala agora dependem exemplos tais modelos estatísticos modelos geralmente robustos dados informações desconhecidas especialmente entrada contém erros comum dados mundo real produzem resultados confiáveis integrados sistemas maiores compreendem múltiplas tarefas muitos sucessos iniciais notáveis ocorreram campo tradução automática devido especialmente trabalho pesquisa ibm desenvolveu modelos estatísticos elaborados sistemas capazes tirar proveito corpora textuais multilíngues existentes produzidos parlamento canadá união europeia resultado leis exigem tradução todos processos governamentais todas línguas oficiais países entanto maioria sistemas dependia corpora desenvolvido especificamente tarefas implementadas sistemas muitas vezes continua sendo grande limitação sucesso resultado grande quantidade pesquisa passou quantidades dados limitadas métodos aprendizagem eficazes pesquisas recentes têm concentrado cada vez algoritmos aprendizagem semi-supervisionados supervisão algoritmos capazes aprender dados anotados manualmente respostas desejadas usando combinação dados anotados anotados geralmente tarefa trabalhosa aprendizagem supervisionada normalmente produz resultados menos precisos quantidade específica dados entrada entanto enorme quantidade dados anotados disponíveis incluindo outras coisas todo conteúdo world wide web muitas vezes pode compensar resultados inferiores \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_frequency = nltk.FreqDist(nltk.word_tokenize(processed_text))\n",
        "word_frequency"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yk6AXAa-AeGC",
        "outputId": "46949d9e-dd57-4555-fd5f-13e53058142b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({\"''\": 6,\n",
              "          '1950': 1,\n",
              "          '1954': 1,\n",
              "          '1964': 1,\n",
              "          '1966': 1,\n",
              "          '1966.': 1,\n",
              "          '1970': 1,\n",
              "          '1975': 1,\n",
              "          '1976': 1,\n",
              "          '1977': 1,\n",
              "          '1978': 2,\n",
              "          '1979': 1,\n",
              "          '1980': 2,\n",
              "          '1981': 1,\n",
              "          '2': 1,\n",
              "          '3': 1,\n",
              "          '60': 1,\n",
              "          '80': 1,\n",
              "          '``': 6,\n",
              "          'abordagem': 1,\n",
              "          'afirmaram': 1,\n",
              "          'agora': 2,\n",
              "          'alan': 1,\n",
              "          'algoritmos': 4,\n",
              "          'alguns': 4,\n",
              "          'alpac': 1,\n",
              "          'and': 1,\n",
              "          'anos': 5,\n",
              "          'anotados': 4,\n",
              "          'antigos': 1,\n",
              "          'aprender': 1,\n",
              "          'aprendizado': 2,\n",
              "          'aprendizagem': 5,\n",
              "          'após': 1,\n",
              "          'artificial': 1,\n",
              "          'artigo': 1,\n",
              "          'atribuição': 1,\n",
              "          'aumento': 1,\n",
              "          'automática': 8,\n",
              "          'autores': 1,\n",
              "          'avanços': 1,\n",
              "          'bancos': 1,\n",
              "          'base': 1,\n",
              "          'baseadas': 1,\n",
              "          'baseava': 1,\n",
              "          'bem': 1,\n",
              "          'blocks': 1,\n",
              "          'cabeça': 2,\n",
              "          'cache': 1,\n",
              "          'cada': 2,\n",
              "          'campo': 1,\n",
              "          'canadá': 1,\n",
              "          'capazes': 2,\n",
              "          'carbonell': 1,\n",
              "          'casos': 1,\n",
              "          'chamado': 1,\n",
              "          'chatterbots': 1,\n",
              "          'chomskyanas': 1,\n",
              "          'cinco': 1,\n",
              "          'ciência': 1,\n",
              "          'coisas': 1,\n",
              "          'combinação': 1,\n",
              "          'começaram': 1,\n",
              "          'começou': 1,\n",
              "          'compensar': 1,\n",
              "          'complexos': 1,\n",
              "          'compreendem': 1,\n",
              "          'compreensão': 3,\n",
              "          'compreensíveis': 1,\n",
              "          'compreensível': 1,\n",
              "          'computacional': 1,\n",
              "          'computador': 1,\n",
              "          'computadores': 3,\n",
              "          'computação': 1,\n",
              "          'computing': 1,\n",
              "          'compõem': 1,\n",
              "          'comum': 1,\n",
              "          'conceituais': 1,\n",
              "          'concentrado': 1,\n",
              "          'concentrava': 1,\n",
              "          'conduzidas': 1,\n",
              "          'confiáveis': 1,\n",
              "          'conhecimento': 1,\n",
              "          'conjuntos': 1,\n",
              "          'conseguiu': 1,\n",
              "          'constante': 1,\n",
              "          'constatou': 1,\n",
              "          'conteúdo': 1,\n",
              "          'continua': 1,\n",
              "          'contém': 1,\n",
              "          'convertem': 2,\n",
              "          'corpora': 2,\n",
              "          'corpus': 1,\n",
              "          'criava': 1,\n",
              "          'critério': 1,\n",
              "          'cujos': 1,\n",
              "          'cullingford': 1,\n",
              "          'dados': 10,\n",
              "          'decisão': 1,\n",
              "          'decisões': 1,\n",
              "          'dentro': 1,\n",
              "          'dependem': 1,\n",
              "          'dependia': 1,\n",
              "          'desafios': 1,\n",
              "          'desconhecidas': 1,\n",
              "          'desejadas': 1,\n",
              "          'desenvolveu': 1,\n",
              "          'desenvolvido': 1,\n",
              "          'desenvolvidos': 2,\n",
              "          'desestimularam': 1,\n",
              "          'devido': 2,\n",
              "          'dez': 1,\n",
              "          'diminuição': 1,\n",
              "          'disponíveis': 1,\n",
              "          'diz': 1,\n",
              "          'dominância': 1,\n",
              "          'drasticamente': 1,\n",
              "          'durante': 1,\n",
              "          'década': 3,\n",
              "          'dói': 2,\n",
              "          'eficazes': 1,\n",
              "          'elaborados': 1,\n",
              "          'eliza': 3,\n",
              "          'emoção': 1,\n",
              "          'enorme': 1,\n",
              "          'entanto': 5,\n",
              "          'entrada': 3,\n",
              "          'então': 1,\n",
              "          'envolveu': 1,\n",
              "          'erros': 1,\n",
              "          'escrever': 1,\n",
              "          'escrita': 1,\n",
              "          'escritas': 1,\n",
              "          'escritos': 1,\n",
              "          'especialmente': 2,\n",
              "          'especificamente': 1,\n",
              "          'específica': 1,\n",
              "          'estatísticos': 4,\n",
              "          'estruturaram': 1,\n",
              "          'estuda': 1,\n",
              "          'estudo': 1,\n",
              "          'europeia': 1,\n",
              "          'excedia': 1,\n",
              "          'exemplo': 1,\n",
              "          'exemplos': 2,\n",
              "          'exigem': 1,\n",
              "          'existentes': 2,\n",
              "          'expectativas': 1,\n",
              "          'experiência': 1,\n",
              "          'extraiam': 1,\n",
              "          'facilmente': 1,\n",
              "          'fala': 2,\n",
              "          'fazer': 1,\n",
              "          'final': 2,\n",
              "          'financiamento': 1,\n",
              "          'formais': 1,\n",
              "          'fornecia': 1,\n",
              "          'frases': 1,\n",
              "          'fundamentos': 1,\n",
              "          'genérica': 1,\n",
              "          'georgetown': 1,\n",
              "          'geralmente': 2,\n",
              "          'gerativa': 1,\n",
              "          'geração': 3,\n",
              "          'governamentais': 1,\n",
              "          'gradual': 1,\n",
              "          'gramática': 1,\n",
              "          'grande': 2,\n",
              "          'história': 1,\n",
              "          'humana': 3,\n",
              "          'humanas': 2,\n",
              "          'humano': 1,\n",
              "          'ibm': 1,\n",
              "          'implementadas': 1,\n",
              "          'incluindo': 1,\n",
              "          'inferiores': 1,\n",
              "          'informação': 3,\n",
              "          'informações': 1,\n",
              "          'inglês': 1,\n",
              "          'iniciais': 1,\n",
              "          'integrados': 1,\n",
              "          'inteligência': 2,\n",
              "          'intelligence': 1,\n",
              "          'interações': 1,\n",
              "          'introduziu': 1,\n",
              "          'introdução': 1,\n",
              "          'jabberwacky': 1,\n",
              "          'joseph': 1,\n",
              "          'lehnert': 2,\n",
              "          'lei': 1,\n",
              "          'leis': 1,\n",
              "          'lentos': 1,\n",
              "          'limitadas': 1,\n",
              "          'limitação': 1,\n",
              "          'linguagem': 6,\n",
              "          'linguística': 2,\n",
              "          'linguístico': 1,\n",
              "          'língua': 6,\n",
              "          'línguas': 2,\n",
              "          'machinery': 1,\n",
              "          'maiores': 1,\n",
              "          'maioria': 2,\n",
              "          'manipuláveis': 1,\n",
              "          'manualmente': 1,\n",
              "          'manuscritas': 1,\n",
              "          'marcação': 1,\n",
              "          'margie': 1,\n",
              "          'markov': 1,\n",
              "          'meehan': 1,\n",
              "          'menos': 1,\n",
              "          'modelos': 6,\n",
              "          'moore': 1,\n",
              "          'muitas': 2,\n",
              "          'muitos': 4,\n",
              "          'multilíngues': 1,\n",
              "          'mundo': 2,\n",
              "          'máquina': 1,\n",
              "          'máquinas': 1,\n",
              "          'mão': 1,\n",
              "          'métodos': 1,\n",
              "          'múltiplas': 1,\n",
              "          'naturais': 1,\n",
              "          'natural': 7,\n",
              "          'neste': 1,\n",
              "          'normalmente': 1,\n",
              "          'notáveis': 1,\n",
              "          'ocorreram': 1,\n",
              "          'ocorrências': 1,\n",
              "          'ocultos': 1,\n",
              "          'oficiais': 1,\n",
              "          'ontologias': 1,\n",
              "          'outras': 1,\n",
              "          'paciente': 1,\n",
              "          'pam': 1,\n",
              "          'parlamento': 1,\n",
              "          'parry': 1,\n",
              "          'part-of-speech': 1,\n",
              "          'partes': 1,\n",
              "          'partir': 1,\n",
              "          'passou': 1,\n",
              "          'países': 1,\n",
              "          'pensamento': 1,\n",
              "          'período': 1,\n",
              "          'pesos': 1,\n",
              "          'pesquisa': 4,\n",
              "          'pesquisas': 2,\n",
              "          'pln': 7,\n",
              "          'plot': 1,\n",
              "          'pode': 1,\n",
              "          'poder': 1,\n",
              "          'politics': 1,\n",
              "          'pouca': 1,\n",
              "          'poucas': 1,\n",
              "          'precisos': 1,\n",
              "          'previsto': 1,\n",
              "          'primeiros': 1,\n",
              "          'probabilísticas': 1,\n",
              "          'problema': 1,\n",
              "          'problemas': 1,\n",
              "          'processamento': 3,\n",
              "          'processos': 1,\n",
              "          'produz': 1,\n",
              "          'produzem': 1,\n",
              "          'produziam': 1,\n",
              "          'produzidos': 1,\n",
              "          'programa': 1,\n",
              "          'programadores': 1,\n",
              "          'programas': 1,\n",
              "          'propunha': 1,\n",
              "          'proveito': 1,\n",
              "          'psicoterapeuta': 1,\n",
              "          'publicou': 1,\n",
              "          'quais': 1,\n",
              "          'qualm': 1,\n",
              "          'quantidade': 3,\n",
              "          'quantidades': 1,\n",
              "          'quanto': 1,\n",
              "          'racter': 1,\n",
              "          'reais': 2,\n",
              "          'real': 2,\n",
              "          'recentes': 1,\n",
              "          'reconhecimento': 1,\n",
              "          'recursos': 1,\n",
              "          'reduzido': 1,\n",
              "          'regras': 3,\n",
              "          'relatório': 1,\n",
              "          'representações': 1,\n",
              "          'resolvido': 1,\n",
              "          'respondendo': 1,\n",
              "          'resposta': 1,\n",
              "          'respostas': 1,\n",
              "          'restrito': 1,\n",
              "          'resultado': 2,\n",
              "          'resultados': 3,\n",
              "          'revolução': 1,\n",
              "          'robustos': 1,\n",
              "          'russas': 1,\n",
              "          'rígidas': 1,\n",
              "          'sam': 1,\n",
              "          'satisfazer': 1,\n",
              "          'schank': 1,\n",
              "          'semelhantes': 1,\n",
              "          'semi-supervisionados': 1,\n",
              "          'sendo': 1,\n",
              "          'sentido': 1,\n",
              "          'ser': 1,\n",
              "          'sessenta': 1,\n",
              "          'shrdlu': 1,\n",
              "          'simulação': 1,\n",
              "          'sistema': 1,\n",
              "          'sistemas': 11,\n",
              "          'sobre': 2,\n",
              "          'suaves': 1,\n",
              "          'subjacente': 1,\n",
              "          'subárea': 1,\n",
              "          'sucedidos': 1,\n",
              "          'sucesso': 1,\n",
              "          'sucessos': 1,\n",
              "          'supervisionada': 1,\n",
              "          'supervisão': 1,\n",
              "          'surpreendentemente': 1,\n",
              "          'tagging': 1,\n",
              "          'tais': 1,\n",
              "          'talespin': 1,\n",
              "          'tanto': 1,\n",
              "          'tarefa': 1,\n",
              "          'tarefas': 2,\n",
              "          'teorias': 1,\n",
              "          'teste': 1,\n",
              "          'textuais': 1,\n",
              "          'teóricos': 1,\n",
              "          'tipo': 1,\n",
              "          'tirar': 1,\n",
              "          'todas': 1,\n",
              "          'todo': 1,\n",
              "          'todos': 1,\n",
              "          'tomam': 1,\n",
              "          'trabalhava': 1,\n",
              "          'trabalho': 1,\n",
              "          'trabalhosa': 1,\n",
              "          'tradução': 7,\n",
              "          'três': 1,\n",
              "          'turing': 2,\n",
              "          'têm': 1,\n",
              "          'units': 1,\n",
              "          'união': 1,\n",
              "          'usando': 2,\n",
              "          'uso': 1,\n",
              "          'ver': 1,\n",
              "          'vez': 2,\n",
              "          'vezes': 2,\n",
              "          'vocabulário': 1,\n",
              "          'web': 1,\n",
              "          'weizenbaum': 1,\n",
              "          'wide': 1,\n",
              "          'wilensky': 1,\n",
              "          'world': 1,\n",
              "          'worlds': 1,\n",
              "          'árvores': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_frequency[\"possuir\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RNBp2u1AiNn",
        "outputId": "5121607b-098d-4976-ce4e-0655e09ed507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_frequency  = max(word_frequency.values())\n",
        "max_frequency"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5wYWztoLoog",
        "outputId": "6beaeaf5-3f43-4897-cbf8-b825179e5f79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in word_frequency:\n",
        "    word_frequency[word] = word_frequency[word]/max_frequency \n",
        "word_frequency"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZMRbSaxPMuL",
        "outputId": "e1da484c-ad6f-4bec-cfd7-5e2007651f5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({\"''\": 0.5454545454545454,\n",
              "          '1950': 0.09090909090909091,\n",
              "          '1954': 0.09090909090909091,\n",
              "          '1964': 0.09090909090909091,\n",
              "          '1966': 0.09090909090909091,\n",
              "          '1966.': 0.09090909090909091,\n",
              "          '1970': 0.09090909090909091,\n",
              "          '1975': 0.09090909090909091,\n",
              "          '1976': 0.09090909090909091,\n",
              "          '1977': 0.09090909090909091,\n",
              "          '1978': 0.18181818181818182,\n",
              "          '1979': 0.09090909090909091,\n",
              "          '1980': 0.18181818181818182,\n",
              "          '1981': 0.09090909090909091,\n",
              "          '2': 0.09090909090909091,\n",
              "          '3': 0.09090909090909091,\n",
              "          '60': 0.09090909090909091,\n",
              "          '80': 0.09090909090909091,\n",
              "          '``': 0.5454545454545454,\n",
              "          'abordagem': 0.09090909090909091,\n",
              "          'afirmaram': 0.09090909090909091,\n",
              "          'agora': 0.18181818181818182,\n",
              "          'alan': 0.09090909090909091,\n",
              "          'algoritmos': 0.36363636363636365,\n",
              "          'alguns': 0.36363636363636365,\n",
              "          'alpac': 0.09090909090909091,\n",
              "          'and': 0.09090909090909091,\n",
              "          'anos': 0.45454545454545453,\n",
              "          'anotados': 0.36363636363636365,\n",
              "          'antigos': 0.09090909090909091,\n",
              "          'aprender': 0.09090909090909091,\n",
              "          'aprendizado': 0.18181818181818182,\n",
              "          'aprendizagem': 0.45454545454545453,\n",
              "          'após': 0.09090909090909091,\n",
              "          'artificial': 0.09090909090909091,\n",
              "          'artigo': 0.09090909090909091,\n",
              "          'atribuição': 0.09090909090909091,\n",
              "          'aumento': 0.09090909090909091,\n",
              "          'automática': 0.7272727272727273,\n",
              "          'autores': 0.09090909090909091,\n",
              "          'avanços': 0.09090909090909091,\n",
              "          'bancos': 0.09090909090909091,\n",
              "          'base': 0.09090909090909091,\n",
              "          'baseadas': 0.09090909090909091,\n",
              "          'baseava': 0.09090909090909091,\n",
              "          'bem': 0.09090909090909091,\n",
              "          'blocks': 0.09090909090909091,\n",
              "          'cabeça': 0.18181818181818182,\n",
              "          'cache': 0.09090909090909091,\n",
              "          'cada': 0.18181818181818182,\n",
              "          'campo': 0.09090909090909091,\n",
              "          'canadá': 0.09090909090909091,\n",
              "          'capazes': 0.18181818181818182,\n",
              "          'carbonell': 0.09090909090909091,\n",
              "          'casos': 0.09090909090909091,\n",
              "          'chamado': 0.09090909090909091,\n",
              "          'chatterbots': 0.09090909090909091,\n",
              "          'chomskyanas': 0.09090909090909091,\n",
              "          'cinco': 0.09090909090909091,\n",
              "          'ciência': 0.09090909090909091,\n",
              "          'coisas': 0.09090909090909091,\n",
              "          'combinação': 0.09090909090909091,\n",
              "          'começaram': 0.09090909090909091,\n",
              "          'começou': 0.09090909090909091,\n",
              "          'compensar': 0.09090909090909091,\n",
              "          'complexos': 0.09090909090909091,\n",
              "          'compreendem': 0.09090909090909091,\n",
              "          'compreensão': 0.2727272727272727,\n",
              "          'compreensíveis': 0.09090909090909091,\n",
              "          'compreensível': 0.09090909090909091,\n",
              "          'computacional': 0.09090909090909091,\n",
              "          'computador': 0.09090909090909091,\n",
              "          'computadores': 0.2727272727272727,\n",
              "          'computação': 0.09090909090909091,\n",
              "          'computing': 0.09090909090909091,\n",
              "          'compõem': 0.09090909090909091,\n",
              "          'comum': 0.09090909090909091,\n",
              "          'conceituais': 0.09090909090909091,\n",
              "          'concentrado': 0.09090909090909091,\n",
              "          'concentrava': 0.09090909090909091,\n",
              "          'conduzidas': 0.09090909090909091,\n",
              "          'confiáveis': 0.09090909090909091,\n",
              "          'conhecimento': 0.09090909090909091,\n",
              "          'conjuntos': 0.09090909090909091,\n",
              "          'conseguiu': 0.09090909090909091,\n",
              "          'constante': 0.09090909090909091,\n",
              "          'constatou': 0.09090909090909091,\n",
              "          'conteúdo': 0.09090909090909091,\n",
              "          'continua': 0.09090909090909091,\n",
              "          'contém': 0.09090909090909091,\n",
              "          'convertem': 0.18181818181818182,\n",
              "          'corpora': 0.18181818181818182,\n",
              "          'corpus': 0.09090909090909091,\n",
              "          'criava': 0.09090909090909091,\n",
              "          'critério': 0.09090909090909091,\n",
              "          'cujos': 0.09090909090909091,\n",
              "          'cullingford': 0.09090909090909091,\n",
              "          'dados': 0.9090909090909091,\n",
              "          'decisão': 0.09090909090909091,\n",
              "          'decisões': 0.09090909090909091,\n",
              "          'dentro': 0.09090909090909091,\n",
              "          'dependem': 0.09090909090909091,\n",
              "          'dependia': 0.09090909090909091,\n",
              "          'desafios': 0.09090909090909091,\n",
              "          'desconhecidas': 0.09090909090909091,\n",
              "          'desejadas': 0.09090909090909091,\n",
              "          'desenvolveu': 0.09090909090909091,\n",
              "          'desenvolvido': 0.09090909090909091,\n",
              "          'desenvolvidos': 0.18181818181818182,\n",
              "          'desestimularam': 0.09090909090909091,\n",
              "          'devido': 0.18181818181818182,\n",
              "          'dez': 0.09090909090909091,\n",
              "          'diminuição': 0.09090909090909091,\n",
              "          'disponíveis': 0.09090909090909091,\n",
              "          'diz': 0.09090909090909091,\n",
              "          'dominância': 0.09090909090909091,\n",
              "          'drasticamente': 0.09090909090909091,\n",
              "          'durante': 0.09090909090909091,\n",
              "          'década': 0.2727272727272727,\n",
              "          'dói': 0.18181818181818182,\n",
              "          'eficazes': 0.09090909090909091,\n",
              "          'elaborados': 0.09090909090909091,\n",
              "          'eliza': 0.2727272727272727,\n",
              "          'emoção': 0.09090909090909091,\n",
              "          'enorme': 0.09090909090909091,\n",
              "          'entanto': 0.45454545454545453,\n",
              "          'entrada': 0.2727272727272727,\n",
              "          'então': 0.09090909090909091,\n",
              "          'envolveu': 0.09090909090909091,\n",
              "          'erros': 0.09090909090909091,\n",
              "          'escrever': 0.09090909090909091,\n",
              "          'escrita': 0.09090909090909091,\n",
              "          'escritas': 0.09090909090909091,\n",
              "          'escritos': 0.09090909090909091,\n",
              "          'especialmente': 0.18181818181818182,\n",
              "          'especificamente': 0.09090909090909091,\n",
              "          'específica': 0.09090909090909091,\n",
              "          'estatísticos': 0.36363636363636365,\n",
              "          'estruturaram': 0.09090909090909091,\n",
              "          'estuda': 0.09090909090909091,\n",
              "          'estudo': 0.09090909090909091,\n",
              "          'europeia': 0.09090909090909091,\n",
              "          'excedia': 0.09090909090909091,\n",
              "          'exemplo': 0.09090909090909091,\n",
              "          'exemplos': 0.18181818181818182,\n",
              "          'exigem': 0.09090909090909091,\n",
              "          'existentes': 0.18181818181818182,\n",
              "          'expectativas': 0.09090909090909091,\n",
              "          'experiência': 0.09090909090909091,\n",
              "          'extraiam': 0.09090909090909091,\n",
              "          'facilmente': 0.09090909090909091,\n",
              "          'fala': 0.18181818181818182,\n",
              "          'fazer': 0.09090909090909091,\n",
              "          'final': 0.18181818181818182,\n",
              "          'financiamento': 0.09090909090909091,\n",
              "          'formais': 0.09090909090909091,\n",
              "          'fornecia': 0.09090909090909091,\n",
              "          'frases': 0.09090909090909091,\n",
              "          'fundamentos': 0.09090909090909091,\n",
              "          'genérica': 0.09090909090909091,\n",
              "          'georgetown': 0.09090909090909091,\n",
              "          'geralmente': 0.18181818181818182,\n",
              "          'gerativa': 0.09090909090909091,\n",
              "          'geração': 0.2727272727272727,\n",
              "          'governamentais': 0.09090909090909091,\n",
              "          'gradual': 0.09090909090909091,\n",
              "          'gramática': 0.09090909090909091,\n",
              "          'grande': 0.18181818181818182,\n",
              "          'história': 0.09090909090909091,\n",
              "          'humana': 0.2727272727272727,\n",
              "          'humanas': 0.18181818181818182,\n",
              "          'humano': 0.09090909090909091,\n",
              "          'ibm': 0.09090909090909091,\n",
              "          'implementadas': 0.09090909090909091,\n",
              "          'incluindo': 0.09090909090909091,\n",
              "          'inferiores': 0.09090909090909091,\n",
              "          'informação': 0.2727272727272727,\n",
              "          'informações': 0.09090909090909091,\n",
              "          'inglês': 0.09090909090909091,\n",
              "          'iniciais': 0.09090909090909091,\n",
              "          'integrados': 0.09090909090909091,\n",
              "          'inteligência': 0.18181818181818182,\n",
              "          'intelligence': 0.09090909090909091,\n",
              "          'interações': 0.09090909090909091,\n",
              "          'introduziu': 0.09090909090909091,\n",
              "          'introdução': 0.09090909090909091,\n",
              "          'jabberwacky': 0.09090909090909091,\n",
              "          'joseph': 0.09090909090909091,\n",
              "          'lehnert': 0.18181818181818182,\n",
              "          'lei': 0.09090909090909091,\n",
              "          'leis': 0.09090909090909091,\n",
              "          'lentos': 0.09090909090909091,\n",
              "          'limitadas': 0.09090909090909091,\n",
              "          'limitação': 0.09090909090909091,\n",
              "          'linguagem': 0.5454545454545454,\n",
              "          'linguística': 0.18181818181818182,\n",
              "          'linguístico': 0.09090909090909091,\n",
              "          'língua': 0.5454545454545454,\n",
              "          'línguas': 0.18181818181818182,\n",
              "          'machinery': 0.09090909090909091,\n",
              "          'maiores': 0.09090909090909091,\n",
              "          'maioria': 0.18181818181818182,\n",
              "          'manipuláveis': 0.09090909090909091,\n",
              "          'manualmente': 0.09090909090909091,\n",
              "          'manuscritas': 0.09090909090909091,\n",
              "          'marcação': 0.09090909090909091,\n",
              "          'margie': 0.09090909090909091,\n",
              "          'markov': 0.09090909090909091,\n",
              "          'meehan': 0.09090909090909091,\n",
              "          'menos': 0.09090909090909091,\n",
              "          'modelos': 0.5454545454545454,\n",
              "          'moore': 0.09090909090909091,\n",
              "          'muitas': 0.18181818181818182,\n",
              "          'muitos': 0.36363636363636365,\n",
              "          'multilíngues': 0.09090909090909091,\n",
              "          'mundo': 0.18181818181818182,\n",
              "          'máquina': 0.09090909090909091,\n",
              "          'máquinas': 0.09090909090909091,\n",
              "          'mão': 0.09090909090909091,\n",
              "          'métodos': 0.09090909090909091,\n",
              "          'múltiplas': 0.09090909090909091,\n",
              "          'naturais': 0.09090909090909091,\n",
              "          'natural': 0.6363636363636364,\n",
              "          'neste': 0.09090909090909091,\n",
              "          'normalmente': 0.09090909090909091,\n",
              "          'notáveis': 0.09090909090909091,\n",
              "          'ocorreram': 0.09090909090909091,\n",
              "          'ocorrências': 0.09090909090909091,\n",
              "          'ocultos': 0.09090909090909091,\n",
              "          'oficiais': 0.09090909090909091,\n",
              "          'ontologias': 0.09090909090909091,\n",
              "          'outras': 0.09090909090909091,\n",
              "          'paciente': 0.09090909090909091,\n",
              "          'pam': 0.09090909090909091,\n",
              "          'parlamento': 0.09090909090909091,\n",
              "          'parry': 0.09090909090909091,\n",
              "          'part-of-speech': 0.09090909090909091,\n",
              "          'partes': 0.09090909090909091,\n",
              "          'partir': 0.09090909090909091,\n",
              "          'passou': 0.09090909090909091,\n",
              "          'países': 0.09090909090909091,\n",
              "          'pensamento': 0.09090909090909091,\n",
              "          'período': 0.09090909090909091,\n",
              "          'pesos': 0.09090909090909091,\n",
              "          'pesquisa': 0.36363636363636365,\n",
              "          'pesquisas': 0.18181818181818182,\n",
              "          'pln': 0.6363636363636364,\n",
              "          'plot': 0.09090909090909091,\n",
              "          'pode': 0.09090909090909091,\n",
              "          'poder': 0.09090909090909091,\n",
              "          'politics': 0.09090909090909091,\n",
              "          'pouca': 0.09090909090909091,\n",
              "          'poucas': 0.09090909090909091,\n",
              "          'precisos': 0.09090909090909091,\n",
              "          'previsto': 0.09090909090909091,\n",
              "          'primeiros': 0.09090909090909091,\n",
              "          'probabilísticas': 0.09090909090909091,\n",
              "          'problema': 0.09090909090909091,\n",
              "          'problemas': 0.09090909090909091,\n",
              "          'processamento': 0.2727272727272727,\n",
              "          'processos': 0.09090909090909091,\n",
              "          'produz': 0.09090909090909091,\n",
              "          'produzem': 0.09090909090909091,\n",
              "          'produziam': 0.09090909090909091,\n",
              "          'produzidos': 0.09090909090909091,\n",
              "          'programa': 0.09090909090909091,\n",
              "          'programadores': 0.09090909090909091,\n",
              "          'programas': 0.09090909090909091,\n",
              "          'propunha': 0.09090909090909091,\n",
              "          'proveito': 0.09090909090909091,\n",
              "          'psicoterapeuta': 0.09090909090909091,\n",
              "          'publicou': 0.09090909090909091,\n",
              "          'quais': 0.09090909090909091,\n",
              "          'qualm': 0.09090909090909091,\n",
              "          'quantidade': 0.2727272727272727,\n",
              "          'quantidades': 0.09090909090909091,\n",
              "          'quanto': 0.09090909090909091,\n",
              "          'racter': 0.09090909090909091,\n",
              "          'reais': 0.18181818181818182,\n",
              "          'real': 0.18181818181818182,\n",
              "          'recentes': 0.09090909090909091,\n",
              "          'reconhecimento': 0.09090909090909091,\n",
              "          'recursos': 0.09090909090909091,\n",
              "          'reduzido': 0.09090909090909091,\n",
              "          'regras': 0.2727272727272727,\n",
              "          'relatório': 0.09090909090909091,\n",
              "          'representações': 0.09090909090909091,\n",
              "          'resolvido': 0.09090909090909091,\n",
              "          'respondendo': 0.09090909090909091,\n",
              "          'resposta': 0.09090909090909091,\n",
              "          'respostas': 0.09090909090909091,\n",
              "          'restrito': 0.09090909090909091,\n",
              "          'resultado': 0.18181818181818182,\n",
              "          'resultados': 0.2727272727272727,\n",
              "          'revolução': 0.09090909090909091,\n",
              "          'robustos': 0.09090909090909091,\n",
              "          'russas': 0.09090909090909091,\n",
              "          'rígidas': 0.09090909090909091,\n",
              "          'sam': 0.09090909090909091,\n",
              "          'satisfazer': 0.09090909090909091,\n",
              "          'schank': 0.09090909090909091,\n",
              "          'semelhantes': 0.09090909090909091,\n",
              "          'semi-supervisionados': 0.09090909090909091,\n",
              "          'sendo': 0.09090909090909091,\n",
              "          'sentido': 0.09090909090909091,\n",
              "          'ser': 0.09090909090909091,\n",
              "          'sessenta': 0.09090909090909091,\n",
              "          'shrdlu': 0.09090909090909091,\n",
              "          'simulação': 0.09090909090909091,\n",
              "          'sistema': 0.09090909090909091,\n",
              "          'sistemas': 1.0,\n",
              "          'sobre': 0.18181818181818182,\n",
              "          'suaves': 0.09090909090909091,\n",
              "          'subjacente': 0.09090909090909091,\n",
              "          'subárea': 0.09090909090909091,\n",
              "          'sucedidos': 0.09090909090909091,\n",
              "          'sucesso': 0.09090909090909091,\n",
              "          'sucessos': 0.09090909090909091,\n",
              "          'supervisionada': 0.09090909090909091,\n",
              "          'supervisão': 0.09090909090909091,\n",
              "          'surpreendentemente': 0.09090909090909091,\n",
              "          'tagging': 0.09090909090909091,\n",
              "          'tais': 0.09090909090909091,\n",
              "          'talespin': 0.09090909090909091,\n",
              "          'tanto': 0.09090909090909091,\n",
              "          'tarefa': 0.09090909090909091,\n",
              "          'tarefas': 0.18181818181818182,\n",
              "          'teorias': 0.09090909090909091,\n",
              "          'teste': 0.09090909090909091,\n",
              "          'textuais': 0.09090909090909091,\n",
              "          'teóricos': 0.09090909090909091,\n",
              "          'tipo': 0.09090909090909091,\n",
              "          'tirar': 0.09090909090909091,\n",
              "          'todas': 0.09090909090909091,\n",
              "          'todo': 0.09090909090909091,\n",
              "          'todos': 0.09090909090909091,\n",
              "          'tomam': 0.09090909090909091,\n",
              "          'trabalhava': 0.09090909090909091,\n",
              "          'trabalho': 0.09090909090909091,\n",
              "          'trabalhosa': 0.09090909090909091,\n",
              "          'tradução': 0.6363636363636364,\n",
              "          'três': 0.09090909090909091,\n",
              "          'turing': 0.18181818181818182,\n",
              "          'têm': 0.09090909090909091,\n",
              "          'units': 0.09090909090909091,\n",
              "          'união': 0.09090909090909091,\n",
              "          'usando': 0.18181818181818182,\n",
              "          'uso': 0.09090909090909091,\n",
              "          'ver': 0.09090909090909091,\n",
              "          'vez': 0.18181818181818182,\n",
              "          'vezes': 0.18181818181818182,\n",
              "          'vocabulário': 0.09090909090909091,\n",
              "          'web': 0.09090909090909091,\n",
              "          'weizenbaum': 0.09090909090909091,\n",
              "          'wide': 0.09090909090909091,\n",
              "          'wilensky': 0.09090909090909091,\n",
              "          'world': 0.09090909090909091,\n",
              "          'worlds': 0.09090909090909091,\n",
              "          'árvores': 0.09090909090909091})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_list_base = nltk.sent_tokenize(text_base)\n",
        "sent_list_base"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDsL4oCQPn9U",
        "outputId": "b3a2d4b9-452b-48f0-c41b-8e5733327592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Processamento de língua natural (PLN) é uma subárea da ciência da computação, inteligência artificial e da linguística que estuda os problemas da geração e compreensão automática de línguas humanas naturais.',\n",
              " 'Sistemas de geração de língua natural convertem informação de bancos de dados de computadores em linguagem compreensível ao ser humano e sistemas de compreensão de língua natural convertem ocorrências de linguagem humana em representações mais formais, mais facilmente manipuláveis por programas de computador.',\n",
              " 'Alguns desafios do PLN são compreensão de língua natural, fazer com que computadores extraiam sentido de linguagem humana ou natural e geração de língua natural.',\n",
              " 'A história do PLN começou na década de 1950, quando Alan Turing publicou o artigo \"Computing Machinery and Intelligence\", que propunha o que agora é chamado de teste de Turing como critério de inteligência.',\n",
              " 'Em 1954, a experiência de Georgetown envolveu a tradução automática de mais de sessenta frases russas para o inglês.',\n",
              " 'Os autores afirmaram que dentro de três ou cinco anos a tradução automática seria um problema resolvido.',\n",
              " '[2] No entanto, os avanços reais foram muito mais lentos do que o previsto e, após o relatório ALPAC em 1966, que constatou que a pesquisa de dez anos não conseguiu satisfazer as expectativas, o financiamento para este estudo em tradução automática foi reduzido drasticamente.',\n",
              " 'Poucas pesquisas em tradução automática foram conduzidas até o final dos anos 80, quando os primeiros sistemas estatísticos de tradução foram desenvolvidos.',\n",
              " 'Alguns sistemas de PLN bem sucedidos desenvolvidos nos anos 60 foram SHRDLU, um sistema de língua natural que trabalhava em \"blocks worlds\" com vocabulário restrito e ELIZA, uma simulação de um psicoterapeuta escrita por Joseph Weizenbaum entre 1964 e 1966.',\n",
              " 'Usando pouca informação sobre o pensamento ou a emoção humana, ELIZA criava, em alguns casos, interações surpreendentemente humanas.',\n",
              " 'Quando o \"paciente\" excedia a base de conhecimento do programa, ELIZA fornecia uma resposta genérica, por exemplo, respondendo a \"Minha cabeça dói\" com \"Por que você diz que sua cabeça dói?\".',\n",
              " 'Durante a década de 1970, muitos programadores começaram a escrever \"ontologias conceituais\", que estruturaram a informação do mundo real em dados compreensíveis por computadores.',\n",
              " 'Exemplos são MARGIE (SCHANK, 1975), SAM (CULLINGFORD, 1978), PAM (WILENSKY, 1978), TaleSpin (MEEHAN, 1976), QUALM (LEHNERT, 1977), Politics (CARBONELL, 1979) e Plot Units (LEHNERT, 1981 ).',\n",
              " 'Neste período, muitos chatterbots foram escritos, como PARRY, Racter e Jabberwacky.',\n",
              " 'Até a década de 1980, a maioria dos sistemas de PLN se baseava em conjuntos complexos de regras manuscritas.',\n",
              " 'A partir do final dos anos 1980, no entanto, houve uma revolução no PLN com a introdução de algoritmos de aprendizagem automática (aprendizado de máquina) para o processamento de linguagem.',\n",
              " 'Isto foi devido tanto ao aumento constante do poder computacional (ver Lei de Moore) quanto à diminuição gradual da dominância das teorias da linguística chomskyanas (como a gramática gerativa), cujos fundamentos teóricos desestimularam o tipo de corpus linguístico que está subjacente à abordagem da aprendizagem automática ao processamento da linguagem[3].',\n",
              " 'Alguns dos algoritmos de aprendizado de máquinas mais antigos, como as árvores de decisão, produziam sistemas de regras rígidas então semelhantes às regras existentes na escritas à mão.',\n",
              " 'No entanto, a marcação de partes da fala (part-of-speech tagging) introduziu o uso de modelos ocultos de Markov para o PLN e, cada vez mais, a pesquisa se concentrava em modelos estatísticos, que tomam decisões suaves e probabilísticas baseadas na atribuição de pesos reais aos recursos que compõem dados de entrada.',\n",
              " 'Os modelos de linguagem de cache, sobre os quais muitos sistemas de reconhecimento de fala agora dependem, são exemplos de tais modelos estatísticos.',\n",
              " 'Esses modelos são geralmente mais robustos quando dados informações desconhecidas, especialmente entrada que contém erros (como é muito comum para dados do mundo real) e produzem resultados mais confiáveis quando integrados em sistemas maiores que compreendem múltiplas tarefas.',\n",
              " 'Muitos dos sucessos iniciais notáveis ocorreram no campo da tradução automática, devido especialmente ao trabalho de pesquisa da IBM, que desenvolveu modelos estatísticos mais elaborados.',\n",
              " 'Estes sistemas foram capazes de tirar proveito de corpora textuais multilíngues existentes produzidos pelo Parlamento do Canadá e a União Europeia como resultado de leis que exigem a tradução de todos os processos governamentais em todas as línguas oficiais dos países.',\n",
              " 'No entanto, a maioria dos sistemas dependia de corpora desenvolvido especificamente para tarefas implementadas por esses sistemas, o que era (e muitas vezes continua sendo) uma grande limitação no sucesso dos mesmo.',\n",
              " 'Como resultado, uma grande quantidade de pesquisa passou de quantidades de dados limitadas a métodos de aprendizagem mais eficazes.',\n",
              " 'Pesquisas recentes têm se concentrado cada vez mais em algoritmos de aprendizagem semi-supervisionados e sem supervisão.',\n",
              " 'Esses algoritmos são capazes de aprender com dados que não foram anotados manualmente com as respostas desejadas ou usando uma combinação de dados anotados e não anotados.',\n",
              " 'Geralmente, esta tarefa é muito mais trabalhosa do que a aprendizagem supervisionada e normalmente produz resultados menos precisos para uma quantidade específica de dados de entrada.',\n",
              " 'No entanto, há uma enorme quantidade de dados não anotados disponíveis (incluindo, entre outras coisas, todo o conteúdo da World Wide Web), que muitas vezes pode compensar os resultados inferiores.']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sent_notes = {}\n",
        "for sent in sent_list_base:\n",
        "    sent_procesed  = pre_process(sent)\n",
        "    note = 0 \n",
        "    for word in nltk.word_tokenize(sent_procesed):\n",
        "        note +=  word_frequency[word]\n",
        "    \n",
        "    sent_notes[sent] = note\n",
        "sent_notes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP84B8eLPz1F",
        "outputId": "24bf2e57-8495-4e2b-a289-faf1fa7643d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'A história do PLN começou na década de 1950, quando Alan Turing publicou o artigo \"Computing Machinery and Intelligence\", que propunha o que agora é chamado de teste de Turing como critério de inteligência.': 3.9999999999999987,\n",
              " 'A partir do final dos anos 1980, no entanto, houve uma revolução no PLN com a introdução de algoritmos de aprendizagem automática (aprendizado de máquina) para o processamento de linguagem.': 4.818181818181818,\n",
              " 'Alguns desafios do PLN são compreensão de língua natural, fazer com que computadores extraiam sentido de linguagem humana ou natural e geração de língua natural.': 6.0,\n",
              " 'Alguns dos algoritmos de aprendizado de máquinas mais antigos, como as árvores de decisão, produziam sistemas de regras rígidas então semelhantes às regras existentes na escritas à mão.': 3.545454545454544,\n",
              " 'Alguns sistemas de PLN bem sucedidos desenvolvidos nos anos 60 foram SHRDLU, um sistema de língua natural que trabalhava em \"blocks worlds\" com vocabulário restrito e ELIZA, uma simulação de um psicoterapeuta escrita por Joseph Weizenbaum entre 1964 e 1966.': 6.727272727272725,\n",
              " 'Até a década de 1980, a maioria dos sistemas de PLN se baseava em conjuntos complexos de regras manuscritas.': 2.9090909090909083,\n",
              " 'Como resultado, uma grande quantidade de pesquisa passou de quantidades de dados limitadas a métodos de aprendizagem mais eficazes.': 2.818181818181818,\n",
              " 'Durante a década de 1970, muitos programadores começaram a escrever \"ontologias conceituais\", que estruturaram a informação do mundo real em dados compreensíveis por computadores.': 4.363636363636362,\n",
              " 'Em 1954, a experiência de Georgetown envolveu a tradução automática de mais de sessenta frases russas para o inglês.': 2.090909090909091,\n",
              " 'Esses algoritmos são capazes de aprender com dados que não foram anotados manualmente com as respostas desejadas ou usando uma combinação de dados anotados e não anotados.': 4.090909090909091,\n",
              " 'Esses modelos são geralmente mais robustos quando dados informações desconhecidas, especialmente entrada que contém erros (como é muito comum para dados do mundo real) e produzem resultados mais confiáveis quando integrados em sistemas maiores que compreendem múltiplas tarefas.': 5.909090909090907,\n",
              " 'Estes sistemas foram capazes de tirar proveito de corpora textuais multilíngues existentes produzidos pelo Parlamento do Canadá e a União Europeia como resultado de leis que exigem a tradução de todos os processos governamentais em todas as línguas oficiais dos países.': 4.09090909090909,\n",
              " 'Exemplos são MARGIE (SCHANK, 1975), SAM (CULLINGFORD, 1978), PAM (WILENSKY, 1978), TaleSpin (MEEHAN, 1976), QUALM (LEHNERT, 1977), Politics (CARBONELL, 1979) e Plot Units (LEHNERT, 1981 ).': 2.545454545454545,\n",
              " 'Geralmente, esta tarefa é muito mais trabalhosa do que a aprendizagem supervisionada e normalmente produz resultados menos precisos para uma quantidade específica de dados de entrada.': 3.090909090909091,\n",
              " 'Isto foi devido tanto ao aumento constante do poder computacional (ver Lei de Moore) quanto à diminuição gradual da dominância das teorias da linguística chomskyanas (como a gramática gerativa), cujos fundamentos teóricos desestimularam o tipo de corpus linguístico que está subjacente à abordagem da aprendizagem automática ao processamento da linguagem[3].': 4.727272727272726,\n",
              " 'Muitos dos sucessos iniciais notáveis ocorreram no campo da tradução automática, devido especialmente ao trabalho de pesquisa da IBM, que desenvolveu modelos estatísticos mais elaborados.': 4.181818181818181,\n",
              " 'Neste período, muitos chatterbots foram escritos, como PARRY, Racter e Jabberwacky.': 1.0,\n",
              " 'No entanto, a maioria dos sistemas dependia de corpora desenvolvido especificamente para tarefas implementadas por esses sistemas, o que era (e muitas vezes continua sendo) uma grande limitação no sucesso dos mesmo.': 4.272727272727272,\n",
              " 'No entanto, a marcação de partes da fala (part-of-speech tagging) introduziu o uso de modelos ocultos de Markov para o PLN e, cada vez mais, a pesquisa se concentrava em modelos estatísticos, que tomam decisões suaves e probabilísticas baseadas na atribuição de pesos reais aos recursos que compõem dados de entrada.': 6.454545454545452,\n",
              " 'No entanto, há uma enorme quantidade de dados não anotados disponíveis (incluindo, entre outras coisas, todo o conteúdo da World Wide Web), que muitas vezes pode compensar os resultados inferiores.': 3.8181818181818166,\n",
              " 'Os autores afirmaram que dentro de três ou cinco anos a tradução automática seria um problema resolvido.': 2.454545454545454,\n",
              " 'Os modelos de linguagem de cache, sobre os quais muitos sistemas de reconhecimento de fala agora dependem, são exemplos de tais modelos estatísticos.': 4.545454545454544,\n",
              " 'Pesquisas recentes têm se concentrado cada vez mais em algoritmos de aprendizagem semi-supervisionados e sem supervisão.': 1.8181818181818183,\n",
              " 'Poucas pesquisas em tradução automática foram conduzidas até o final dos anos 80, quando os primeiros sistemas estatísticos de tradução foram desenvolvidos.': 4.727272727272727,\n",
              " 'Processamento de língua natural (PLN) é uma subárea da ciência da computação, inteligência artificial e da linguística que estuda os problemas da geração e compreensão automática de línguas humanas naturais.': 4.727272727272726,\n",
              " 'Quando o \"paciente\" excedia a base de conhecimento do programa, ELIZA fornecia uma resposta genérica, por exemplo, respondendo a \"Minha cabeça dói\" com \"Por que você diz que sua cabeça dói?\".': 5.272727272727272,\n",
              " 'Sistemas de geração de língua natural convertem informação de bancos de dados de computadores em linguagem compreensível ao ser humano e sistemas de compreensão de língua natural convertem ocorrências de linguagem humana em representações mais formais, mais facilmente manipuláveis por programas de computador.': 9.090909090909095,\n",
              " 'Usando pouca informação sobre o pensamento ou a emoção humana, ELIZA criava, em alguns casos, interações surpreendentemente humanas.': 2.3636363636363633,\n",
              " '[2] No entanto, os avanços reais foram muito mais lentos do que o previsto e, após o relatório ALPAC em 1966, que constatou que a pesquisa de dez anos não conseguiu satisfazer as expectativas, o financiamento para este estudo em tradução automática foi reduzido drasticamente.': 4.363636363636362}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "\n",
        "bests_sent = heapq.nlargest(5,sent_notes, key = sent_notes.get)\n",
        "print('\\n'.join(bests_sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r59B5rBKRjSO",
        "outputId": "7f4ddfb1-4e18-4223-94ba-38292be36955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sistemas de geração de língua natural convertem informação de bancos de dados de computadores em linguagem compreensível ao ser humano e sistemas de compreensão de língua natural convertem ocorrências de linguagem humana em representações mais formais, mais facilmente manipuláveis por programas de computador.\n",
            "Alguns sistemas de PLN bem sucedidos desenvolvidos nos anos 60 foram SHRDLU, um sistema de língua natural que trabalhava em \"blocks worlds\" com vocabulário restrito e ELIZA, uma simulação de um psicoterapeuta escrita por Joseph Weizenbaum entre 1964 e 1966.\n",
            "No entanto, a marcação de partes da fala (part-of-speech tagging) introduziu o uso de modelos ocultos de Markov para o PLN e, cada vez mais, a pesquisa se concentrava em modelos estatísticos, que tomam decisões suaves e probabilísticas baseadas na atribuição de pesos reais aos recursos que compõem dados de entrada.\n",
            "Alguns desafios do PLN são compreensão de língua natural, fazer com que computadores extraiam sentido de linguagem humana ou natural e geração de língua natural.\n",
            "Esses modelos são geralmente mais robustos quando dados informações desconhecidas, especialmente entrada que contém erros (como é muito comum para dados do mundo real) e produzem resultados mais confiáveis quando integrados em sistemas maiores que compreendem múltiplas tarefas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_base)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4y1PaAiSGDB",
        "outputId": "da16d415-baa1-4c8e-c908-427c1cd9534a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processamento de língua natural (PLN) é uma subárea da ciência da computação, inteligência artificial e da linguística que estuda os problemas da geração e compreensão automática de línguas humanas naturais. Sistemas de geração de língua natural convertem informação de bancos de dados de computadores em linguagem compreensível ao ser humano e sistemas de compreensão de língua natural convertem ocorrências de linguagem humana em representações mais formais, mais facilmente manipuláveis por programas de computador. Alguns desafios do PLN são compreensão de língua natural, fazer com que computadores extraiam sentido de linguagem humana ou natural e geração de língua natural.\n",
            "A história do PLN começou na década de 1950, quando Alan Turing publicou o artigo \"Computing Machinery and Intelligence\", que propunha o que agora é chamado de teste de Turing como critério de inteligência.\n",
            "Em 1954, a experiência de Georgetown envolveu a tradução automática de mais de sessenta frases russas para o inglês. Os autores afirmaram que dentro de três ou cinco anos a tradução automática seria um problema resolvido.[2] No entanto, os avanços reais foram muito mais lentos do que o previsto e, após o relatório ALPAC em 1966, que constatou que a pesquisa de dez anos não conseguiu satisfazer as expectativas, o financiamento para este estudo em tradução automática foi reduzido drasticamente. Poucas pesquisas em tradução automática foram conduzidas até o final dos anos 80, quando os primeiros sistemas estatísticos de tradução foram desenvolvidos.\n",
            "Alguns sistemas de PLN bem sucedidos desenvolvidos nos anos 60 foram SHRDLU, um sistema de língua natural que trabalhava em \"blocks worlds\" com vocabulário restrito e ELIZA, uma simulação de um psicoterapeuta escrita por Joseph Weizenbaum entre 1964 e 1966. Usando pouca informação sobre o pensamento ou a emoção humana, ELIZA criava, em alguns casos, interações surpreendentemente humanas. Quando o \"paciente\" excedia a base de conhecimento do programa, ELIZA fornecia uma resposta genérica, por exemplo, respondendo a \"Minha cabeça dói\" com \"Por que você diz que sua cabeça dói?\".\n",
            "Durante a década de 1970, muitos programadores começaram a escrever \"ontologias conceituais\", que estruturaram a informação do mundo real em dados compreensíveis por computadores. Exemplos são MARGIE (SCHANK, 1975), SAM (CULLINGFORD, 1978), PAM (WILENSKY, 1978), TaleSpin (MEEHAN, 1976), QUALM (LEHNERT, 1977), Politics (CARBONELL, 1979) e Plot Units (LEHNERT, 1981 ). Neste período, muitos chatterbots foram escritos, como PARRY, Racter e Jabberwacky.\n",
            "Até a década de 1980, a maioria dos sistemas de PLN se baseava em conjuntos complexos de regras manuscritas. A partir do final dos anos 1980, no entanto, houve uma revolução no PLN com a introdução de algoritmos de aprendizagem automática (aprendizado de máquina) para o processamento de linguagem. Isto foi devido tanto ao aumento constante do poder computacional (ver Lei de Moore) quanto à diminuição gradual da dominância das teorias da linguística chomskyanas (como a gramática gerativa), cujos fundamentos teóricos desestimularam o tipo de corpus linguístico que está subjacente à abordagem da aprendizagem automática ao processamento da linguagem[3].\n",
            "Alguns dos algoritmos de aprendizado de máquinas mais antigos, como as árvores de decisão, produziam sistemas de regras rígidas então semelhantes às regras existentes na escritas à mão. No entanto, a marcação de partes da fala (part-of-speech tagging) introduziu o uso de modelos ocultos de Markov para o PLN e, cada vez mais, a pesquisa se concentrava em modelos estatísticos, que tomam decisões suaves e probabilísticas baseadas na atribuição de pesos reais aos recursos que compõem dados de entrada. Os modelos de linguagem de cache, sobre os quais muitos sistemas de reconhecimento de fala agora dependem, são exemplos de tais modelos estatísticos. Esses modelos são geralmente mais robustos quando dados informações desconhecidas, especialmente entrada que contém erros (como é muito comum para dados do mundo real) e produzem resultados mais confiáveis quando integrados em sistemas maiores que compreendem múltiplas tarefas.\n",
            "Muitos dos sucessos iniciais notáveis ocorreram no campo da tradução automática, devido especialmente ao trabalho de pesquisa da IBM, que desenvolveu modelos estatísticos mais elaborados. Estes sistemas foram capazes de tirar proveito de corpora textuais multilíngues existentes produzidos pelo Parlamento do Canadá e a União Europeia como resultado de leis que exigem a tradução de todos os processos governamentais em todas as línguas oficiais dos países. No entanto, a maioria dos sistemas dependia de corpora desenvolvido especificamente para tarefas implementadas por esses sistemas, o que era (e muitas vezes continua sendo) uma grande limitação no sucesso dos mesmo. Como resultado, uma grande quantidade de pesquisa passou de quantidades de dados limitadas a métodos de aprendizagem mais eficazes.\n",
            "Pesquisas recentes têm se concentrado cada vez mais em algoritmos de aprendizagem semi-supervisionados e sem supervisão. Esses algoritmos são capazes de aprender com dados que não foram anotados manualmente com as respostas desejadas ou usando uma combinação de dados anotados e não anotados. Geralmente, esta tarefa é muito mais trabalhosa do que a aprendizagem supervisionada e normalmente produz resultados menos precisos para uma quantidade específica de dados de entrada. No entanto, há uma enorme quantidade de dados não anotados disponíveis (incluindo, entre outras coisas, todo o conteúdo da World Wide Web), que muitas vezes pode compensar os resultados inferiores.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n'.join(bests_sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIT1pjWMSO2U",
        "outputId": "435cded8-7882-446e-e375-afa045acd3d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sistemas de geração de língua natural convertem informação de bancos de dados de computadores em linguagem compreensível ao ser humano e sistemas de compreensão de língua natural convertem ocorrências de linguagem humana em representações mais formais, mais facilmente manipuláveis por programas de computador.\n",
            "Alguns sistemas de PLN bem sucedidos desenvolvidos nos anos 60 foram SHRDLU, um sistema de língua natural que trabalhava em \"blocks worlds\" com vocabulário restrito e ELIZA, uma simulação de um psicoterapeuta escrita por Joseph Weizenbaum entre 1964 e 1966.\n",
            "No entanto, a marcação de partes da fala (part-of-speech tagging) introduziu o uso de modelos ocultos de Markov para o PLN e, cada vez mais, a pesquisa se concentrava em modelos estatísticos, que tomam decisões suaves e probabilísticas baseadas na atribuição de pesos reais aos recursos que compõem dados de entrada.\n",
            "Alguns desafios do PLN são compreensão de língua natural, fazer com que computadores extraiam sentido de linguagem humana ou natural e geração de língua natural.\n",
            "Esses modelos são geralmente mais robustos quando dados informações desconhecidas, especialmente entrada que contém erros (como é muito comum para dados do mundo real) e produzem resultados mais confiáveis quando integrados em sistemas maiores que compreendem múltiplas tarefas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import HTML\n",
        "\n",
        "final_text = '<H1>Resumo</H1>'\n",
        "for sent in sent_list_base:\n",
        "    if sent in bests_sent:\n",
        "        final_text +=str(sent).replace(sent,f\"<mark>{sent}</mark>\")\n",
        "    else:\n",
        "        final_text += sent\n",
        "display(HTML(f\"\"\"{final_text}\"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "fMurR7A-Tr84",
        "outputId": "34212aaa-10cc-4e3b-9be0-48dc097f062e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<H1>Resumo</H1>Processamento de língua natural (PLN) é uma subárea da ciência da computação, inteligência artificial e da linguística que estuda os problemas da geração e compreensão automática de línguas humanas naturais.<mark>Sistemas de geração de língua natural convertem informação de bancos de dados de computadores em linguagem compreensível ao ser humano e sistemas de compreensão de língua natural convertem ocorrências de linguagem humana em representações mais formais, mais facilmente manipuláveis por programas de computador.</mark><mark>Alguns desafios do PLN são compreensão de língua natural, fazer com que computadores extraiam sentido de linguagem humana ou natural e geração de língua natural.</mark>A história do PLN começou na década de 1950, quando Alan Turing publicou o artigo \"Computing Machinery and Intelligence\", que propunha o que agora é chamado de teste de Turing como critério de inteligência.Em 1954, a experiência de Georgetown envolveu a tradução automática de mais de sessenta frases russas para o inglês.Os autores afirmaram que dentro de três ou cinco anos a tradução automática seria um problema resolvido.[2] No entanto, os avanços reais foram muito mais lentos do que o previsto e, após o relatório ALPAC em 1966, que constatou que a pesquisa de dez anos não conseguiu satisfazer as expectativas, o financiamento para este estudo em tradução automática foi reduzido drasticamente.Poucas pesquisas em tradução automática foram conduzidas até o final dos anos 80, quando os primeiros sistemas estatísticos de tradução foram desenvolvidos.<mark>Alguns sistemas de PLN bem sucedidos desenvolvidos nos anos 60 foram SHRDLU, um sistema de língua natural que trabalhava em \"blocks worlds\" com vocabulário restrito e ELIZA, uma simulação de um psicoterapeuta escrita por Joseph Weizenbaum entre 1964 e 1966.</mark>Usando pouca informação sobre o pensamento ou a emoção humana, ELIZA criava, em alguns casos, interações surpreendentemente humanas.Quando o \"paciente\" excedia a base de conhecimento do programa, ELIZA fornecia uma resposta genérica, por exemplo, respondendo a \"Minha cabeça dói\" com \"Por que você diz que sua cabeça dói?\".Durante a década de 1970, muitos programadores começaram a escrever \"ontologias conceituais\", que estruturaram a informação do mundo real em dados compreensíveis por computadores.Exemplos são MARGIE (SCHANK, 1975), SAM (CULLINGFORD, 1978), PAM (WILENSKY, 1978), TaleSpin (MEEHAN, 1976), QUALM (LEHNERT, 1977), Politics (CARBONELL, 1979) e Plot Units (LEHNERT, 1981 ).Neste período, muitos chatterbots foram escritos, como PARRY, Racter e Jabberwacky.Até a década de 1980, a maioria dos sistemas de PLN se baseava em conjuntos complexos de regras manuscritas.A partir do final dos anos 1980, no entanto, houve uma revolução no PLN com a introdução de algoritmos de aprendizagem automática (aprendizado de máquina) para o processamento de linguagem.Isto foi devido tanto ao aumento constante do poder computacional (ver Lei de Moore) quanto à diminuição gradual da dominância das teorias da linguística chomskyanas (como a gramática gerativa), cujos fundamentos teóricos desestimularam o tipo de corpus linguístico que está subjacente à abordagem da aprendizagem automática ao processamento da linguagem[3].Alguns dos algoritmos de aprendizado de máquinas mais antigos, como as árvores de decisão, produziam sistemas de regras rígidas então semelhantes às regras existentes na escritas à mão.<mark>No entanto, a marcação de partes da fala (part-of-speech tagging) introduziu o uso de modelos ocultos de Markov para o PLN e, cada vez mais, a pesquisa se concentrava em modelos estatísticos, que tomam decisões suaves e probabilísticas baseadas na atribuição de pesos reais aos recursos que compõem dados de entrada.</mark>Os modelos de linguagem de cache, sobre os quais muitos sistemas de reconhecimento de fala agora dependem, são exemplos de tais modelos estatísticos.<mark>Esses modelos são geralmente mais robustos quando dados informações desconhecidas, especialmente entrada que contém erros (como é muito comum para dados do mundo real) e produzem resultados mais confiáveis quando integrados em sistemas maiores que compreendem múltiplas tarefas.</mark>Muitos dos sucessos iniciais notáveis ocorreram no campo da tradução automática, devido especialmente ao trabalho de pesquisa da IBM, que desenvolveu modelos estatísticos mais elaborados.Estes sistemas foram capazes de tirar proveito de corpora textuais multilíngues existentes produzidos pelo Parlamento do Canadá e a União Europeia como resultado de leis que exigem a tradução de todos os processos governamentais em todas as línguas oficiais dos países.No entanto, a maioria dos sistemas dependia de corpora desenvolvido especificamente para tarefas implementadas por esses sistemas, o que era (e muitas vezes continua sendo) uma grande limitação no sucesso dos mesmo.Como resultado, uma grande quantidade de pesquisa passou de quantidades de dados limitadas a métodos de aprendizagem mais eficazes.Pesquisas recentes têm se concentrado cada vez mais em algoritmos de aprendizagem semi-supervisionados e sem supervisão.Esses algoritmos são capazes de aprender com dados que não foram anotados manualmente com as respostas desejadas ou usando uma combinação de dados anotados e não anotados.Geralmente, esta tarefa é muito mais trabalhosa do que a aprendizagem supervisionada e normalmente produz resultados menos precisos para uma quantidade específica de dados de entrada.No entanto, há uma enorme quantidade de dados não anotados disponíveis (incluindo, entre outras coisas, todo o conteúdo da World Wide Web), que muitas vezes pode compensar os resultados inferiores."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sumarização com Algoritmo de Luhn"
      ],
      "metadata": {
        "id": "iyGLPvL2F-KT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install goose3\n",
        "!python -m spacy download pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goq0aBNbGX2i",
        "outputId": "ecde8087-02fe-415a-f2af-b619b2b49262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: goose3 in /usr/local/lib/python3.7/dist-packages (3.1.11)\n",
            "Requirement already satisfied: cssselect in /usr/local/lib/python3.7/dist-packages (from goose3) (1.1.0)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (from goose3) (1.0.9)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from goose3) (4.2.6)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from goose3) (4.6.3)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from goose3) (0.42.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from goose3) (2.23.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from goose3) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from goose3) (2.8.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from goose3) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect->goose3) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->goose3) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->goose3) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->goose3) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->goose3) (2021.10.8)\n",
            "Collecting pt_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.5/pt_core_news_sm-2.2.5.tar.gz (21.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.2 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from pt_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.21.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.9.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.2.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.4)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/pt_core_news_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/pt\n",
            "You can now load the model via spacy.load('pt')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import HTML\n",
        "from goose3 import Goose\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import heapq\n",
        "import spacy"
      ],
      "metadata": {
        "id": "wlRaXWOKGC_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "spa_NLP = spacy.load('pt')\n",
        "spa_NLP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPw6LK-JGZvD",
        "outputId": "2be87844-b713-4bca-a56d-d4431e25a404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.pt.Portuguese at 0x7f5b848b8350>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = nltk.corpus.stopwords.words('portuguese')"
      ],
      "metadata": {
        "id": "4Jg-_wwcGmeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_process(text_base):\n",
        "    text = re.sub(r'\\s+',' ',text_base.lower())\n",
        "    text = re.sub(r'[0-9]', \" \", text)\n",
        "\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    # tokens = []\n",
        "    # for token in spa_NLP(text):\n",
        "    #     tokens.append(token.lemma_)\n",
        "\n",
        "    new_text = \"\"\n",
        "    for i in tokens:\n",
        "        if not  i in stopwords and not i in string.punctuation:\n",
        "            new_text += f\"{i} \"\n",
        "\n",
        "    return new_text"
      ],
      "metadata": {
        "id": "FO0hIpTrGsjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sent_value(sent_list,top_words, dist):\n",
        "    values = []\n",
        "    idx_sent = 0\n",
        "    for sent in sent_list:\n",
        "        word_list = nltk.word_tokenize(sent)\n",
        "        idx_words = []\n",
        "        for word in top_words:\n",
        "            try:\n",
        "                idx_words.append(word_list.index(word))\n",
        "            except ValueError:\n",
        "                pass\n",
        "        idx_words.sort()\n",
        "        print(idx_words)\n",
        "        # for word in  nltk.word_tokenize(sent):"
      ],
      "metadata": {
        "id": "CNHh8IYAZg33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarization(text_base, top_words = 5, dist=2):\n",
        "    sent_list_base = nltk.sent_tokenize(text_base)\n",
        "    processed_sent_list = [pre_process(sent) for sent in sent_list_base]\n",
        "\n",
        "    words = [word for sent in processed_sent_list for word in nltk.word_tokenize(sent) ]\n",
        "\n",
        "    word_frequency = nltk.FreqDist(words)\n",
        "\n",
        "    top_words =  [word[0] for word in word_frequency.most_common(top_words)]\n",
        "\n",
        "    sent_value(processed_sent_list,top_words,dist)\n"
      ],
      "metadata": {
        "id": "lj31BlEaWgUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_base = \"\"\"A inteligência artificial é a inteligência similar à humana máquinas.\n",
        "Definem como o estudo de agente artificial com inteligência.\n",
        "Ciência e engenharia de produzir máquinas com inteligência.\n",
        "Resolver problemas e possuir inteligência. \n",
        "Relacionada ao comportamento inteligente.\n",
        "Construção de máquinas para raciocinar. \n",
        "Aprender com os erros e acertos.\n",
        "Inteligência artificial é raciocinar nas situações do cotidiano.\"\"\""
      ],
      "metadata": {
        "id": "imNWUNPlGyCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarization(text_base)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZieEqh3Xk23",
        "outputId": "82375a5d-1fe1-4814-99c5-9fbf3746eca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['inteligência', 'artificial', 'inteligência', 'similar', 'humana', 'máquinas']\n",
            "inteligência\n",
            "artificial\n",
            "máquinas\n",
            "raciocinar\n",
            "similar\n",
            "[0, 1, 3, 5]\n",
            "['definem', 'estudo', 'agente', 'artificial', 'inteligência']\n",
            "inteligência\n",
            "artificial\n",
            "máquinas\n",
            "raciocinar\n",
            "similar\n",
            "[3, 4]\n",
            "['ciência', 'engenharia', 'produzir', 'máquinas', 'inteligência']\n",
            "inteligência\n",
            "artificial\n",
            "máquinas\n",
            "raciocinar\n",
            "similar\n",
            "[3, 4]\n",
            "['resolver', 'problemas', 'possuir', 'inteligência']\n",
            "inteligência\n",
            "artificial\n",
            "máquinas\n",
            "raciocinar\n",
            "similar\n",
            "[3]\n",
            "['relacionada', 'comportamento', 'inteligente']\n",
            "inteligência\n",
            "artificial\n",
            "máquinas\n",
            "raciocinar\n",
            "similar\n",
            "[]\n",
            "['construção', 'máquinas', 'raciocinar']\n",
            "inteligência\n",
            "artificial\n",
            "máquinas\n",
            "raciocinar\n",
            "similar\n",
            "[1, 2]\n",
            "['aprender', 'erros', 'acertos']\n",
            "inteligência\n",
            "artificial\n",
            "máquinas\n",
            "raciocinar\n",
            "similar\n",
            "[]\n",
            "['inteligência', 'artificial', 'raciocinar', 'situações', 'cotidiano']\n",
            "inteligência\n",
            "artificial\n",
            "máquinas\n",
            "raciocinar\n",
            "similar\n",
            "[0, 1, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XzGn0HBBXmCU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}